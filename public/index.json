[{"authors":null,"categories":null,"content":"This feature can be used for publishing content such as:\n Project or software documentation Online courses Tutorials  The parent folder may be renamed, for example, to docs for project documentation or course for creating an online course.\nTo disable this feature, either delete the parent folder, or set draft = true in the front matter of all its pages.\nAfter renaming or deleting the parent folder, you may wish to update any [[menu.main]] menu links to it in the config.toml.\n","date":1536444000,"expirydate":-62135596800,"kind":"section","lang":"de","lastmod":1536444000,"objectID":"c3224f3a64174f08aaf31e1f1d16ffd3","permalink":"/nab/tutorial/","publishdate":"2018-09-09T00:00:00+02:00","relpermalink":"/nab/tutorial/","section":"tutorial","summary":"This feature can be used for publishing content such as:\n Project or software documentation Online courses Tutorials  The parent folder may be renamed, for example, to docs for project documentation or course for creating an online course.\nTo disable this feature, either delete the parent folder, or set draft = true in the front matter of all its pages.\nAfter renaming or deleting the parent folder, you may wish to update any [[menu.","tags":null,"title":"Overview","type":"docs"},{"authors":null,"categories":["Allgemeines"],"content":"\rKlingt ja bedrohlich, aber es ist wirklich Möglich R und Python sinnvoll zu kombinieren. Nicht nur in den Anwendungen, sondern auch beim Erstellen von Skripten mit R markdown.\nZu Beginn des letzten Semesters hatte ich die Idee in der Vorlesung “Mathematischen Grundlagen der Wirtschaftsinformatik” ein paar der Begriffe der Mengenlehre denen daraus abgeleiteten Begriffen der abstrakten Datentypen gegenüberzustellen. So gibt es die Idee der Menge u.a. in Python als set.\nWie aber kann man solche Python-Fragmente in ein R markdown Sktipr einbauen? - Kann man R markdown überhaupt mit Python zusammen bringen? - Ein wenig suchen im Internet und ein paar Stunden später hatte ich es geschaft. Dank einer Netzpython…\nDie Netzpython als Bindeglied zwischen R und Python\rEine Netzpython (engl. reticulated python) stand Pate für den Namen des R Paketes reticulate, welches R und Python miteinander verbindet. So ist es möglich Python-Befehle direkt in ein R markdown Skript ausführen zulassen, diese Fragmente adequat durchzustellen – ganz wie R Skripte – und sogar Daten zwoschen R und Python hin und her (aus) zu tauschen.\nNach der Installation mittels\ninstall.packages(\u0026quot;reticulate\u0026quot;)\rbedarf es aber durch aus noch einiger Anpassungen, bis alles zur Zufriedenheit funktioniert.\nStandardmässig sucht die Netzpython nach ihrem Gefährten mit der Hilfe des Befehls Sys.which(\u0026quot;python\u0026quot;), welcher bei mir leider zu einer vollkommen alten, aber noch benutzen, Python Version führte. Möchte man eine ganz bestimmte Python Version haben, so hilft einem der Befehl use_python():\nlibrary(reticulate)\ruse_python(\u0026quot;/usr/local/bin/python\u0026quot;) # Pfad zum Python-Befehl der benutz werden soll.\rEs werden auch virtuelle Umgebungen unterstützt:\nlibrary(reticulate)\ruse_virtualenv(\u0026quot;myenv\u0026quot;)\rUnd auch eine ganz andere Schlangenart kann benutzt werden, Anacondas:\nlibrary(reticulate)\ruse_condaenv(\u0026quot;mycondaenv\u0026quot;)\r\rDer Einbau in ein R markdown Dokument\rEinen Python Quellcode in ein R markdown einzubauen ist dann wieder sehr einfach. Man ändert einfach ein r in python im Codeblock und schon steht einem der knitr-Chunk als Python Quelle zur Verfügung.\nSp liefert der knitr-Chunk\r```{python}\r# Etwas Python gefällig?\rdef quadrat(x):\rreturn x**2\rprint(quadrat(2))\r```\r\rin einem R markdown, dann die Ausgabe:\n# Etwas Python geföllig?\rdef quadrat(x):\rreturn x**2\rprint(quadrat(2))\r## 4\rDas war es aber noch lange nicht. R und Python können nämlich nicht nur nebeneinander, sondern auch miteinander!\nDazu dann aber mehr in einem späteren Blog-Eintrag.\n\r","date":1543795200,"expirydate":-62135596800,"kind":"page","lang":"de","lastmod":1543795200,"objectID":"128f142baa74ce88d6a32f3eb6c1a5db","permalink":"/nab/post/der-angriff-der-riesenschlangen/","publishdate":"2018-12-03T00:00:00Z","relpermalink":"/nab/post/der-angriff-der-riesenschlangen/","section":"post","summary":"Klingt ja bedrohlich, aber es ist wirklich Möglich R und Python sinnvoll zu kombinieren. Nicht nur in den Anwendungen, sondern auch beim Erstellen von Skripten mit R markdown.\nZu Beginn des letzten Semesters hatte ich die Idee in der Vorlesung “Mathematischen Grundlagen der Wirtschaftsinformatik” ein paar der Begriffe der Mengenlehre denen daraus abgeleiteten Begriffen der abstrakten Datentypen gegenüberzustellen. So gibt es die Idee der Menge u.a. in Python als set.","tags":["Python","R","R markdown","Technisches"],"title":"Der Angriff der Riesenschlangen.","type":"post"},{"authors":null,"categories":null,"content":" In this tutorial, I\u0026rsquo;ll share my top 10 tips for getting started with Academic:\nTip 1 \u0026hellip;\nTip 2 \u0026hellip;\n","date":1536444000,"expirydate":-62135596800,"kind":"page","lang":"de","lastmod":1536444000,"objectID":"6a451186c775f5f0adb3a0416d0cb711","permalink":"/nab/tutorial/example/","publishdate":"2018-09-09T00:00:00+02:00","relpermalink":"/nab/tutorial/example/","section":"tutorial","summary":"In this tutorial, I\u0026rsquo;ll share my top 10 tips for getting started with Academic:\nTip 1 \u0026hellip;\nTip 2 \u0026hellip;","tags":null,"title":"Example Page","type":"docs"},{"authors":null,"categories":null,"content":" Personenbezogene Daten (nachfolgend zumeist nur „Daten“ genannt) werden von uns nur im Rahmen der Erforderlichkeit sowie zum Zwecke der Bereitstellung eines funktionsfähigen und nutzerfreundlichen Internetauftritts, inklusive seiner Inhalte und der dort angebotenen Leistungen, verarbeitet. Gemäß Art. 4 Ziffer 1. der Verordnung (EU) 2016/679, also der Datenschutz-Grundverordnung (nachfolgend nur „DSGVO“ genannt), gilt als „Verarbeitung“ jeder mit oder ohne Hilfe automatisierter Verfahren ausgeführter Vorgang oder jede solche Vorgangsreihe im Zusammenhang mit personenbezogenen Daten, wie das Erheben, das Erfassen, die Organisation, das Ordnen, die Speicherung, die Anpassung oder Veränderung, das Auslesen, das Abfragen, die Verwendung, die Offenlegung durch Übermittlung, Verbreitung oder eine andere Form der Bereitstellung, den Abgleich oder die Verknüpfung, die Einschränkung, das Löschen oder die Vernichtung. Mit der nachfolgenden Datenschutzerklärung informieren wir Sie insbesondere über Art, Umfang, Zweck, Dauer und Rechtsgrundlage der Verarbeitung personenbezogener Daten, soweit wir entweder allein oder gemeinsam mit anderen über die Zwecke und Mittel der Verarbeitung entscheiden. Zudem informieren wir Sie nachfolgend über die von uns zu Optimierungszwecken sowie zur Steigerung der Nutzungsqualität eingesetzten Fremdkomponenten, soweit hierdurch Dritte Daten in wiederum eigener Verantwortung verarbeiten.\nUnsere Datenschutzerklärung ist wie folgt gegliedert:\nI. Informationen über uns als Verantwortliche\nII. Rechte der Nutzer und Betroffenen\nIII. Informationen zur Datenverarbeitung\n\u0026hellip;\nI. Informationen über uns als Verantwortliche Verantwortlicher Anbieter dieses Internetauftritts im datenschutzrechtlichen Sinne ist:\nNorman Markgraf\nGuts-Muths-Weg 19\n45136 Essen\nDeutschland\nTelefon: +49-176-20077335\nE-Mail: admin(at)sefiroth.net\nDatenschutzbeauftragte/r beim Anbieter ist:\nNorman Markgraf\nII. Rechte der Nutzer und Betroffenen Mit Blick auf die nachfolgend noch näher beschriebene Datenverarbeitung haben die Nutzer und Betroffenen das Recht auf Bestätigung, ob sie betreffende Daten verarbeitet werden, auf Auskunft über die verarbeiteten Daten, auf weitere Informationen über die Datenverarbeitung sowie auf Kopien der Daten (vgl. auch Art. 15 DSGVO); auf Berichtigung oder Vervollständigung unrichtiger bzw. unvollständiger Daten (vgl. auch Art. 16 DSGVO); auf unverzügliche Löschung der sie betreffenden Daten (vgl. auch Art. 17 DSGVO), oder, alternativ, soweit eine weitere Verarbeitung gemäß Art. 17 Abs. 3 DSGVO erforderlich ist, auf Einschränkung der Verarbeitung nach Maßgabe von Art. 18 DSGVO; auf Erhalt der sie betreffenden und von ihnen bereitgestellten Daten und auf Übermittlung dieser Daten an andere Anbieter/Verantwortliche (vgl. auch Art. 20 DSGVO); auf Beschwerde gegenüber der Aufsichtsbehörde, sofern sie der Ansicht sind, dass die sie betreffenden Daten durch den Anbieter unter Verstoß gegen datenschutzrechtliche Bestimmungen verarbeitet werden (vgl. auch Art. 77 DSGVO). Darüber hinaus ist der Anbieter dazu verpflichtet, alle Empfänger, denen gegenüber Daten durch den Anbieter offengelegt worden sind, über jedwede Berichtigung oder Löschung von Daten oder die Einschränkung der Verarbeitung, die aufgrund der Artikel 16, 17 Abs. 1, 18 DSGVO erfolgt, zu unterrichten. Diese Verpflichtung besteht jedoch nicht, soweit diese Mitteilung unmöglich oder mit einem unverhältnismäßigen Aufwand verbunden ist. Unbeschadet dessen hat der Nutzer ein Recht auf Auskunft über diese Empfänger. Ebenfalls haben die Nutzer und Betroffenen nach Art. 21 DSGVO das Recht auf Widerspruch gegen die künftige Verarbeitung der sie betreffenden Daten, sofern die Daten durch den Anbieter nach Maßgabe von Art. 6 Abs. 1 lit. f) DSGVO verarbeitet werden. Insbesondere ist ein Widerspruch gegen die Datenverarbeitung zum Zwecke der Direktwerbung statthaft.\nIII. Informationen zur Datenverarbeitung Ihre bei Nutzung unseres Internetauftritts verarbeiteten Daten werden gelöscht oder gesperrt, sobald der Zweck der Speicherung entfällt, der Löschung der Daten keine gesetzlichen Aufbewahrungspflichten entgegenstehen und nachfolgend keine anderslautenden Angaben zu einzelnen Verarbeitungsverfahren gemacht werden.\nCookies\na) Sitzungs-Cookies/Session-Cookies\nWir verwenden mit unserem Internetauftritt sog. Cookies. Cookies sind kleine Textdateien oder andere Speichertechnologien, die durch den von Ihnen eingesetzten Internet-Browser auf Ihrem Endgerät ablegt und gespeichert werden. Durch diese Cookies werden im individuellen Umfang bestimmte Informationen von Ihnen, wie beispielsweise Ihre Browser- oder Standortdaten oder Ihre IP-Adresse, verarbeitet.\nDurch diese Verarbeitung wird unser Internetauftritt benutzerfreundlicher, effektiver und sicherer, da die Verarbeitung bspw. die Wiedergabe unseres Internetauftritts in unterschiedlichen Sprachen oder das Angebot einer Warenkorbfunktion ermöglicht. Rechtsgrundlage dieser Verarbeitung ist Art. 6 Abs. 1 lit b.) DSGVO, sofern diese Cookies Daten zur Vertragsanbahnung oder Vertragsabwicklung verarbeitet werden. Falls die Verarbeitung nicht der Vertragsanbahnung oder Vertragsabwicklung dient, liegt unser berechtigtes Interesse in der Verbesserung der Funktionalität unseres Internetauftritts. Rechtsgrundlage ist in dann Art. 6 Abs. 1 lit. f) DSGVO. Mit Schließen Ihres Internet-Browsers werden diese Session-Cookies gelöscht.\nb) Drittanbieter-Cookies\nGegebenenfalls werden mit unserem Internetauftritt auch Cookies von Partnerunternehmen, mit denen wir zum Zwecke der Werbung, der Analyse oder der Funktionalitäten unseres Internetauftritts zusammenarbeiten, verwendet. Die Einzelheiten hierzu, insbesondere zu den Zwecken und den Rechtsgrundlagen der Verarbeitung solcher Drittanbieter-Cookies, entnehmen Sie bitte den nachfolgenden Informationen.\nc) Beseitigungsmöglichkeit\nSie können die Installation der Cookies durch eine Einstellung Ihres Internet-Browsers verhindern oder einschränken. Ebenfalls können Sie bereits gespeicherte Cookies jederzeit löschen. Die hierfür erforderlichen Schritte und Maßnahmen hängen jedoch von Ihrem konkret genutzten Internet-Browser ab. Bei Fragen benutzen Sie daher bitte die Hilfefunktion oder Dokumentation Ihres Internet-Browsers oder wenden sich an dessen Hersteller bzw. Support. Bei sog. Flash-Cookies kann die Verarbeitung allerdings nicht über die Einstellungen des Browsers unterbunden werden. Stattdessen müssen Sie insoweit die Einstellung Ihres Flash-Players ändern. Auch die hierfür erforderlichen Schritte und Maßnahmen hängen von Ihrem konkret genutzten Flash-Player ab. Bei Fragen benutzen Sie daher bitte ebenso die Hilfefunktion oder Dokumentation Ihres Flash-Players oder wenden sich an den Hersteller bzw. Benutzer-Support. Sollten Sie die Installation der Cookies verhindern oder einschränken, kann dies allerdings dazu führen, dass nicht sämtliche Funktionen unseres Internetauftritts vollumfänglich nutzbar sind.\nGoogle Analytics\nIn unserem Internetauftritt setzen wir Google Analytics ein. Hierbei handelt es sich um einen Webanalysedienst der Google LLC, 1600 Amphitheatre Parkway, Mountain View, CA 94043 USA, nachfolgend nur „Google“ genannt. Durch die Zertifizierung nach dem EU-US-Datenschutzschild („EU-US Privacy Shield“) https://www.privacyshield.gov/participant?id=a2zt000000001L5AAI\u0026amp;status=Active garantiert Google, dass die Datenschutzvorgaben der EU auch bei der Verarbeitung von Daten in den USA eingehalten werden. Der Dienst Google Analytics dient zur Analyse des Nutzungsverhaltens unseres Internetauftritts. Rechtsgrundlage ist Art. 6 Abs. 1 lit. f) DSGVO. Unser berechtigtes Interesse liegt in der Analyse, Optimierung und dem wirtschaftlichen Betrieb unseres Internetauftritts. Nutzungs- und nutzerbezogene Informationen, wie bspw. IP-Adresse, Ort, Zeit oder Häufigkeit des Besuchs unseres Internetauftritts, werden dabei an einen Server von Google in den USA übertragen und dort gespeichert. Allerdings nutzen wir Google Analytics mit der sog. Anonymisierungsfunktion. Durch diese Funktion kürzt Google die IP-Adresse schon innerhalb der EU bzw. des EWR. Die so erhobenen Daten werden wiederum von Google genutzt, um uns eine Auswertung über den Besuch unseres Internetauftritts sowie über die dortigen Nutzungsaktivitäten zur Verfügung zu stellen. Auch können diese Daten genutzt werden, um weitere Dienstleistungen zu erbringen, die mit der Nutzung unseres Internetauftritts und der Nutzung des Internets zusammenhängen. Google gibt an, Ihre IP-Adresse nicht mit anderen Daten zu verbinden. Zudem hält Google unter https://www.google.com/intl/de/policies/privacy/partners weitere datenschutzrechtliche Informationen für Sie bereit, so bspw. auch zu den Möglichkeiten, die Datennutzung zu unterbinden. Zudem bietet Google unter https://tools.google.com/dlpage/gaoptout?hl=de ein sog. Deaktivierungs-Add-on nebst weiteren Informationen hierzu an. Dieses Add-on lässt sich mit den gängigen Internet-Browsern installieren und bietet Ihnen weitergehende Kontrollmöglichkeit über die Daten, die Google bei Aufruf unseres Internetauftritts erfasst. Dabei teilt das Add-on dem JavaScript (ga.js) von Google Analytics mit, dass Informationen zum Besuch unseres Internetauftritts nicht an Google Analytics übermittelt werden sollen. Dies verhindert aber nicht, dass Informationen an uns oder an andere Webanalysedienste übermittelt werden. Ob und welche weiteren Webanalysedienste von uns eingesetzt werden, erfahren Sie natürlich ebenfalls in dieser Datenschutzerklärung.\nGoogle-Maps\nIn unserem Internetauftritt setzen wir Google Maps zur Darstellung unseres Standorts sowie zur Erstellung einer Anfahrtsbeschreibung ein. Es handelt sich hierbei um einen Dienst der Google LLC, 1600 Amphitheatre Parkway, Mountain View, CA 94043 USA, nachfolgend nur „Google“ genannt. Durch die Zertifizierung nach dem EU-US-Datenschutzschild („EU-US Privacy Shield“) https://www.privacyshield.gov/participant?id=a2zt000000001L5AAI\u0026amp;status=Active garantiert Google, dass die Datenschutzvorgaben der EU auch bei der Verarbeitung von Daten in den USA eingehalten werden. Um die Darstellung bestimmter Schriften in unserem Internetauftritt zu ermöglichen, wird bei Aufruf unseres Internetauftritts eine Verbindung zu dem Google-Server in den USA aufgebaut. Sofern Sie die in unseren Internetauftritt eingebundene Komponente Google Maps aufrufen, speichert Google über Ihren Internet-Browser ein Cookie auf Ihrem Endgerät. Um unseren Standort anzuzeigen und eine Anfahrtsbeschreibung zu erstellen, werden Ihre Nutzereinstellungen und -daten verarbeitet. Hierbei können wir nicht ausschließen, dass Google Server in den USA einsetzt. Rechtsgrundlage ist Art. 6 Abs. 1 lit. f) DSGVO. Unser berechtigtes Interesse liegt in der Optimierung der Funktionalität unseres Internetauftritts. Durch die so hergestellte Verbindung zu Google kann Google ermitteln, von welcher Website Ihre Anfrage gesendet worden ist und an welche IP-Adresse die Anfahrtsbeschreibung zu übermitteln ist. Sofern Sie mit dieser Verarbeitung nicht einverstanden sind, haben Sie die Möglichkeit, die Installation der Cookies durch die entsprechenden Einstellungen in Ihrem Internet-Browser zu verhindern. Einzelheiten hierzu finden Sie vorstehend unter dem Punkt „Cookies“. Zudem erfolgt die Nutzung von Google Maps sowie der über Google Maps erlangten Informationen nach den Google-Nutzungsbedingungen https://policies.google.com/terms?gl=DE\u0026amp;hl=de und den Geschäftsbedingungen für Google Maps https://www.google.com/intl/de_de/help/terms_maps.html. Überdies bietet Google unter https://adssettings.google.com/authenticated https://policies.google.com/privacy weitergehende Informationen an.\nGoogle reCAPTCHA\nIn unserem Internetauftritt setzen wir Google reCAPTCHA zur Überprüfung und Vermeidung von Interaktionen auf unserer Internetseite durch automatisierte Zugriffe, bspw. durch sog. Bots, ein. Es handelt sich hierbei um einen Dienst der Google LLC, 1600 Amphitheatre Parkway, Mountain View, CA 94043 USA, nachfolgend nur „Google“ genannt. Durch die Zertifizierung nach dem EU-US-Datenschutzschild („EU-US Privacy Shield“) https://www.privacyshield.gov/participant?id=a2zt000000001L5AAI\u0026amp;status=Active garantiert Google, dass die Datenschutzvorgaben der EU auch bei der Verarbeitung von Daten in den USA eingehalten werden. Durch diesen Dienst kann Google ermitteln, von welcher Webseite eine Anfrage gesendet wird sowie von welcher IP-Adresse aus Sie die sog. reCAPTCHA-Eingabebox verwenden. Neben Ihrer IP-Adresse werden womöglich noch weitere Informationen durch Google erfasst, die für das Angebot und die Gewährleistung dieses Dienstes notwendig sind.\nRechtsgrundlage ist Art. 6 Abs. 1 lit. f) DSGVO. Unser berechtigtes Interesse liegt in der Sicherheit unseres Internetauftritts sowie in der Abwehr unerwünschter, automatisierter Zugriffe in Form von Spam o.ä.. Google bietet unter https://policies.google.com/privacy weitergehende Informationen zu dem allgemeinen Umgang mit Ihren Nutzerdaten an.\nGoogle Fonts\nIn unserem Internetauftritt setzen wir Google Fonts zur Darstellung externer Schriftarten ein. Es handelt sich hierbei um einen Dienst der Google LLC, 1600 Amphitheatre Parkway, Mountain View, CA 94043 USA, nachfolgend nur „Google“ genannt. Durch die Zertifizierung nach dem EU-US-Datenschutzschild („EU-US Privacy Shield“) https://www.privacyshield.gov/participant?id=a2zt000000001L5AAI\u0026amp;status=Active garantiert Google, dass die Datenschutzvorgaben der EU auch bei der Verarbeitung von Daten in den USA eingehalten werden. Um die Darstellung bestimmter Schriften in unserem Internetauftritt zu ermöglichen, wird bei Aufruf unseres Internetauftritts eine Verbindung zu dem Google-Server in den USA aufgebaut. Rechtsgrundlage ist Art. 6 Abs. 1 lit. f) DSGVO. Unser berechtigtes Interesse liegt in der Optimierung und dem wirtschaftlichen Betrieb unseres Internetauftritts. Durch die bei Aufruf unseres Internetauftritts hergestellte Verbindung zu Google kann Google ermitteln, von welcher Website Ihre Anfrage gesendet worden ist und an welche IP-Adresse die Darstellung der Schrift zu übermitteln ist. Google bietet unter https://adssettings.google.com/authenticated https://policies.google.com/privacy weitere Informationen an und zwar insbesondere zu den Möglichkeiten der Unterbindung der Datennutzung.\n„Facebook“-Social-Plug-in\nIn unserem Internetauftritt setzen wir das Plug-in des Social-Networks Facebook ein. Bei Facebook handelt es sich um einen Internetservice der facebook Inc., 1601 S. California Ave, Palo Alto, CA 94304, USA. In der EU wird dieser Service wiederum von der Facebook Ireland Limited, 4 Grand Canal Square, Dublin 2, Irland, betrieben, nachfolgend beide nur „Facebook“ genannt. Durch die Zertifizierung nach dem EU-US-Datenschutzschild („EU-US Privacy Shield“) https://www.privacyshield.gov/participant?id=a2zt0000000GnywAAC\u0026amp;status=Active garantiert Facebook, dass die Datenschutzvorgaben der EU auch bei der Verarbeitung von Daten in den USA eingehalten werden. Rechtsgrundlage ist Art. 6 Abs. 1 lit. f) DSGVO. Unser berechtigtes Interesse liegt in der Qualitätsverbesserung unseres Internetauftritts. Weitergehende Informationen über die möglichen Plug-ins sowie über deren jeweilige Funktionen hält Facebook unter https://developers.facebook.com/docs/plugins/ für Sie bereit.\nSofern das Plug-in auf einer der von Ihnen besuchten Seiten unseres Internetauftritts hinterlegt ist, lädt Ihr Internet-Browser eine Darstellung des Plug-ins von den Servern von Facebook in den USA herunter. Aus technischen Gründen ist es dabei notwendig, dass Facebook Ihre IP-Adresse verarbeitet. Daneben werden aber auch Datum und Uhrzeit des Besuchs unserer Internetseiten erfasst. Sollten Sie bei Facebook eingeloggt sein, während Sie eine unserer mit dem Plug-in versehenen Internetseite besuchen, werden die durch das Plug-in gesammelten Informationen Ihres konkreten Besuchs von Facebook erkannt. Die so gesammelten Informationen weist Facebook womöglich Ihrem dortigen persönlichen Nutzerkonto zu. Sofern Sie also bspw. den sog. „Gefällt mir“-Button von Facebook benutzen, werden diese Informationen in Ihrem Facebook-Nutzerkonto gespeichert und ggf. über die Plattform von Facebook veröffentlicht. Wenn Sie das verhindern möchten, müssen Sie sich entweder vor dem Besuch unseres Internetauftritts bei Facebook ausloggen oder durch den Einsatz eines Add-ons für Ihren Internetbrowser verhindern, dass das Laden des Facebook-Plug-in blockiert wird. Weitergehende Informationen über die Erhebung und Nutzung von Daten sowie Ihre diesbezüglichen Rechte und Schutzmöglichkeiten hält Facebook in den unter https://www.facebook.com/policy.php abrufbaren Datenschutzhinweisen bereit.\n„Twitter“-Social-Plug-in\nIn unserem Internetauftritt setzen wir das Plug-in des Social-Networks Twitter ein. Bei Twitter handelt es sich um einen Internetservice der Twitter Inc., 795 Folsom St., Suite 600, San Francisco, CA 94107, USA, nachfolgend nur „Twitter“ genannt. Durch die Zertifizierung nach dem EU-US-Datenschutzschild („EU-US Privacy Shield“) https://www.privacyshield.gov/participant?id=a2zt0000000TORzAAO\u0026amp;status=Active garantiert Twitter, dass die Datenschutzvorgaben der EU auch bei der Verarbeitung von Daten in den USA eingehalten werden. Rechtsgrundlage ist Art. 6 Abs. 1 lit. f) DSGVO. Unser berechtigtes Interesse liegt in der Qualitätsverbesserung unseres Internetauftritts. Sofern das Plug-in auf einer der von Ihnen besuchten Seiten unseres Internetauftritts hinterlegt ist, lädt Ihr Internet-Browser eine Darstellung des Plug-ins von den Servern von Twitter in den USA herunter. Aus technischen Gründen ist es dabei notwendig, dass Twitter Ihre IP-Adresse verarbeitet. Daneben werden aber auch Datum und Uhrzeit des Besuchs unserer Internetseiten erfasst. Sollten Sie bei Twitter eingeloggt sein, während Sie eine unserer mit dem Plug-in versehenen Internetseite besuchen, werden die durch das Plug-in gesammelten Informationen Ihres konkreten Besuchs von Twitter erkannt. Die so gesammelten Informationen weist Twitter womöglich Ihrem dortigen persönlichen Nutzerkonto zu. Sofern Sie also bspw. den sog. „Teilen“-Button von Twitter benutzen, werden diese Informationen in Ihrem Twitter-Nutzerkonto gespeichert und ggf. über die Plattform von Twitter veröffentlicht. Wenn Sie das verhindern möchten, müssen Sie sich entweder vor dem Besuch unseres Internetauftritts bei Twitter ausloggen oder die entsprechenden Einstellungen in Ihrem Twitter-Benutzerkonto vornehmen. Weitergehende Informationen über die Erhebung und Nutzung von Daten sowie Ihre diesbezüglichen Rechte und Schutzmöglichkeiten hält Twitter in den unter https://twitter.com/privacy abrufbaren Datenschutzhinweisen bereit.\nMuster-Datenschutzerklärung der Anwaltskanzlei Weiß \u0026amp; Partner\n","date":1530136800,"expirydate":-62135596800,"kind":"page","lang":"de","lastmod":1530136800,"objectID":"18d05a63a1c8d7ed973cc51838494e41","permalink":"/nab/privacy/","publishdate":"2018-06-28T00:00:00+02:00","relpermalink":"/nab/privacy/","section":"","summary":"Personenbezogene Daten (nachfolgend zumeist nur „Daten“ genannt) werden von uns nur im Rahmen der Erforderlichkeit sowie zum Zwecke der Bereitstellung eines funktionsfähigen und nutzerfreundlichen Internetauftritts, inklusive seiner Inhalte und der dort angebotenen Leistungen, verarbeitet. Gemäß Art. 4 Ziffer 1. der Verordnung (EU) 2016/679, also der Datenschutz-Grundverordnung (nachfolgend nur „DSGVO“ genannt), gilt als „Verarbeitung“ jeder mit oder ohne Hilfe automatisierter Verfahren ausgeführter Vorgang oder jede solche Vorgangsreihe im Zusammenhang mit personenbezogenen Daten, wie das Erheben, das Erfassen, die Organisation, das Ordnen, die Speicherung, die Anpassung oder Veränderung, das Auslesen, das Abfragen, die Verwendung, die Offenlegung durch Übermittlung, Verbreitung oder eine andere Form der Bereitstellung, den Abgleich oder die Verknüpfung, die Einschränkung, das Löschen oder die Vernichtung.","tags":null,"title":"Datenschutzerklärung (Privacy Policy)","type":"page"},{"authors":null,"categories":["Statistik"],"content":"\rWenn meine Tochter SBI hört, denkt sie an Sally Bollywood Investigation. – Und ich oft auch. – Mit SBI ist hier aber nicht der Trickfilm für Kinder, sondern Simulation Based Inference, gemeint.\nAngestachelt von Prof. Dr. Karsten Lübke und im Schlepptau von Prof. Dr. Oliver Gansser, Prof. Dr. Matthias Gehrke und Prof. Dr. Bianca Krol haben ein paar kluge Köpfe bei der FOM den Unterricht für Statistik auf eine neue Grundlage zu stellen. Und ich habe dabei mitgewirkt.\nUnser Mastermind, Karsten Lübke, hat dazu einen sehr schönen und lesenswerten Blog-Eintrag geschrieben: https://www.causeweb.org/sbi/?p=1559\n","date":1528675200,"expirydate":-62135596800,"kind":"page","lang":"de","lastmod":1528675200,"objectID":"eded8bceb46fc9fd80a8d90ec1566da6","permalink":"/nab/post/sbi-simulation-based-inference/","publishdate":"2018-06-11T00:00:00Z","relpermalink":"/nab/post/sbi-simulation-based-inference/","section":"post","summary":"Wenn meine Tochter SBI hört, denkt sie an Sally Bollywood Investigation. – Und ich oft auch. – Mit SBI ist hier aber nicht der Trickfilm für Kinder, sondern Simulation Based Inference, gemeint.\nAngestachelt von Prof. Dr. Karsten Lübke und im Schlepptau von Prof. Dr. Oliver Gansser, Prof. Dr. Matthias Gehrke und Prof. Dr. Bianca Krol haben ein paar kluge Köpfe bei der FOM den Unterricht für Statistik auf eine neue Grundlage zu stellen.","tags":["Lehre","Allgemein","Statistik"],"title":"SBI - Simulation Based Inference","type":"post"},{"authors":null,"categories":["Allgemeines","Information"],"content":"\rJede Programmiersprache hat Regeln.\rNeben dem Regelwerk welches durch den Syntax einer Sprache festgelegt wird, gib es aber noch Regeln über die Form in der man den Quelltext schreibt.\rDiese sogenannte Stilregeln (engl. style guides) sind von Programmieren aufgestellte Regeln um ein einheitliches “Schriftbild” des Quelltextes zu erhalten.\rDas Ziel der Stilregeln ist es, den Quelltext lesbarer zu gestallten, um leichter Änderungen einzupflegen oder um unnötiges zu vermeiden.\nEine Programmiersprache wie Python zum Beispiel hat mit PEP8 einen eigenen Standard wie ein Python Programm geschrieben seien sollte.\rDazu gibt es auch gleich das passenden Prüfprogramm (früher pep8, neuerdings pycodestyle).\nSchreibt man ein R markdown Text mag man vielleicht nicht daran denken, dass so eine Idee auch hier sehr sinnvoll ist.\rNeben den gängigen Style-Guides für den R Quellcode (z. B.: Google’s R Style Guide, Hadley Wickham’s Advanced R - Style guide, jef.works R Style Guide, R Style Guide oder R-Style-Guide) gibt es aber kaum Regeln (z. B.: Pimp my Rmd) für die Gestaltung von R markdown.\nStil-Regeln für gutes R markdown, ein erster Vorschlag\rKeine unnützen Zeichen am Ende von Textzeilen. / No whitespaces at the end of a line\nEine Textzeile sollte mit einem ‘echtem’ Zeichen enden und nicht mit einem ‘unsichtbarem’ Zeichen.\rDas heisst: Leerzeichen, Tabs, harte Leerzeichen etc. gehören nicht ans Ende einer Zeile.\n\rZwei Leerzeilen vor einer jeden Kopfzeile. / Two blank lines before every header\nUm die Inhalte auch klar voneinander trennen zu können sollte man vor der Kopfzeile zwei Leerzeilen eingefügt werden.\rStatt\n# Das ist eine Kopfzeile auf der 1. Ebene\r## Das is eine Kopfzeile auf der 2. Ebene\rDas hier ist einfacher Text\rsollte es so gegliedert sein:\n\r# Das ist eine Kopfzeile auf der 1. Ebene\r## Das is eine Kopfzeile auf der 2. Ebene\rDas hier ist einfacher Text\rVor und nach Aufzählungen sollte immer eine Leerzeile stehen. / One blank line before and after itemizations or enumerations\nStatt\nDas ist eine Liste:\r- Ein Punkt\r- Ein anderer Punkt\rUnd hier geht der Text weiter.\r1. Der erste Punkt.\r2. Der zweite Punkt.\rUnd wieder mal ein Text.\rsollte es so gegliedert sein:\nDas ist eine Liste:\r- Ein Punkt\r- Ein anderer Punkt\rUnd hier geht der Text weiter.\r1. Der erste Punkt.\r2. Der zweite Punkt.\rUnd wieder mal ein Text.\rVor und nach Codeblöcken sollte immer eine Leerzeile stehen. / One blank line before and after a codeblock\nStatt\n\rEtwas Text vorher\r```{r}1+1\r```und danach.\r\rsollte man es besser wie folgt gliedern:\n\rEtwas Text vorher\r```{r}1+1\r``` und danach.\r\rKeine anderen Sprachen als R markdown für Inhalte oder Design nutzen. / Use no other languages to create content or design, other than (R) markdown.\nKeine anderen Sprachen, insbesondere LaTeX, um besondere Effekte zu erzielen. Dafür sollten (native) DIV oder SPAN Abschnitte benutzt werden und entsprechend durch spätere (Filter-)Programme umgesetzt werden. So ist es immer möglich Design-Ideen für alle möglichen Zielsprachen zu erhalten.\n\r\r\rRmdStyleChecker, ein erster Style Checker für R markdown\rDie ersten drei Punkte der Liste habe ich zu Testzwecken in einem kleinen Projekt mit Hilfe von Python implementiert.\rDen Python-Quelltext findet man unter RmdStyleChecker. Er läuft unter Python 3.5+.\n\r","date":1525219200,"expirydate":-62135596800,"kind":"page","lang":"de","lastmod":1525219200,"objectID":"fbd2d9474dec3dc967107598b9f96114","permalink":"/nab/post/auch-r-markdown-dateien-sollten-sich-an-regeln-halten/","publishdate":"2018-05-02T00:00:00Z","relpermalink":"/nab/post/auch-r-markdown-dateien-sollten-sich-an-regeln-halten/","section":"post","summary":"Jede Programmiersprache hat Regeln.\rNeben dem Regelwerk welches durch den Syntax einer Sprache festgelegt wird, gib es aber noch Regeln über die Form in der man den Quelltext schreibt.\rDiese sogenannte Stilregeln (engl. style guides) sind von Programmieren aufgestellte Regeln um ein einheitliches “Schriftbild” des Quelltextes zu erhalten.\rDas Ziel der Stilregeln ist es, den Quelltext lesbarer zu gestallten, um leichter Änderungen einzupflegen oder um unnötiges zu vermeiden.\nEine Programmiersprache wie Python zum Beispiel hat mit PEP8 einen eigenen Standard wie ein Python Programm geschrieben seien sollte.","tags":["R","Allgemein","R markdown","Python"],"title":"Auch R markdown Dateien sollten sich an Regeln halten","type":"post"},{"authors":null,"categories":["Statistik"],"content":"\rEin Nullhypothesentest ist schnell geschrieben.\rWill man den approximativen Weg gehen, so hilft R einem mit entsprechenden Tests mit einfachen Befehlen.\rNimmt man MOSAIC dazu, so bekommt man u.a. für den Test auf Anteils- oder Mittelwerte sogar einen sehr einfachen, weil einheitlichen, Syntax.\nZwei Beispiele für approximative Hypothesentests mit MOSAIC\rLaden wir unsere Testdaten, die tipping Daten wie folgt:\nlibrary(mosaic)\rdownload.file(\u0026quot;https://goo.gl/whKjnl\u0026quot;, destfile = \u0026quot;tips.csv\u0026quot;)\rtips \u0026lt;- read.csv2(\u0026quot;tips.csv\u0026quot;)\rset.seed(2009)\rDann erstellen wir zwei Forschungsfragen:\nIst der mittlere Frauenanteil unter der Bezahler*innen zu den Zeitpunkten Lunch und Dinner gleich?\rIst der mittlere Rechnungsbetrag zu den Zeitpunkten Lunch und Dinner gleich?\r\rIm ersten Fall ist die Hypothese schnell geschrieben:\n\\[\rH_0 : \\pi_{\\text{Lunch}} = \\pi_{\\text{Dinner}} \\quad\\text{vs.}\\quad H_1 : \\pi_{\\text{Lunch}} \\neq \\pi_{\\text{Dinner}}\r\\]\rDer approximative Test mit R und MOSAIC lautet nun:\nprop.test(sex ~ time, success = \u0026quot;Female\u0026quot;, data = tips)\r## ## 2-sample test for equality of proportions with continuity\r## correction\r## ## data: tally(sex ~ time)\r## X-squared = 9.3438, df = 1, p-value = 0.002237\r## alternative hypothesis: two.sided\r## 95 percent confidence interval:\r## -0.36602563 -0.07247705\r## sample estimates:\r## prop 1 prop 2 ## 0.2954545 0.5147059\rÄhnlich sieht es für den zweiten Fall aus. Die Hypothese lautet hier:\n\\[\rH_0 : \\mu_{Lunch} = \\mu_{Dinner} \\quad\\text{vs.}\\quad H_1 : \\mu_{Lunch} \\neq \\mu_{Dinner}\r\\]\nDer dazugehörige Test lautet dann:\nt.test(total_bill ~ time, data = tips)\r## ## Welch Two Sample t-test\r## ## data: total_bill by time\r## t = 3.123, df = 143.29, p-value = 0.002167\r## alternative hypothesis: true difference in means is not equal to 0\r## 95 percent confidence interval:\r## 1.331877 5.925088\r## sample estimates:\r## mean in group Dinner mean in group Lunch ## 20.79716 17.16868\r\rSimulation der Nullverteilung mit MOSAIC\rEin anderer Weg ist es die Stichprobe selber zu nutzen um daraus eine Verteilung der Nullhypothese (die Nullverteilung) ableiten zu können.\rIm ersten Fall schaut man sich die Anteilsunterschiede an, wenn man die (potentielle) Abhängigkeit von der Tageszeit (Lunch und Dinner) künstlich “abschaltet”:\nset.seed(2009)\rNullVtlgAntwert \u0026lt;- do(10000) * diffprop(sex ~ shuffle(time), success = \u0026quot;Female\u0026quot;, data = tips)\rgf_histogram(~diffprop, nint = 25, data = NullVtlgAntwert)\rSchaut man sich nun die Lage der Anteilsdifferenz der Stichprobe \\(\\hat\\pi=0.2192513\\) in Bezug auf diese Nullverteilung geometrisch an, so kann man schon einen ersten Eindruck erlangen, ob die Nullhypothese abzulehnen ist oder nicht:\ndiffpropdach \u0026lt;- diffprop(sex ~ time, success = \u0026quot;Female\u0026quot;, data = tips)\rgf_histogram(~diffprop, nint = 25, data = NullVtlgAntwert) + geom_vline(xintercept = diffpropdach, color = \u0026quot;blue\u0026quot;)\rOffenbar ist \\(\\hat\\pi\\) kein sehr häufiges Ereignis.\nDer “p-Wert” ist auch leicht ermittelt:\npvalue_aw \u0026lt;- prop(~abs(diffprop) \u0026gt;= abs(diffpropdach), data = NullVtlgAntwert)\rpvalue_aw\r## prop_TRUE ## 0.0027\rÄhnlich sieht die Situation im zweien Fall aus. Mit Hilfe weniger Befehle erzeugen wir die Verteilung.\nset.seed(2009)\rNullVtlgMittelwert \u0026lt;- do(10000) * diffmean(total_bill ~ shuffle(time), data = tips)\rgf_histogram(~diffmean, nint = 25, data = NullVtlgMittelwert)\rUnd können im Anschluss die Mittelwertsdifferenz der Stichprobe geometrisch einordnen:\ndiffmeandach \u0026lt;- diffmean(total_bill ~ time, data = tips)\rgf_histogram(~diffmean, nint = 25, data = NullVtlgMittelwert) + geom_vline(xintercept = diffmeandach, color = \u0026quot;blue\u0026quot;)\rAuch den “p-Wert” können wir nun leicht bestimmen:\npvalue_mw \u0026lt;- prop(~abs(diffmean) \u0026gt;= abs(diffmeandach), data = NullVtlgMittelwert)\rpvalue_mw\r## prop_TRUE ## 0.0039\r\rDas Problem – Zeit\rDas Problem bei der Simulation ist die Zeit, die R braucht um die Nullverteilungen zu generieren.\rDas liegt im wesentlichen an Mosaic.\rMit den Routinen aus FastSimNullDistR lassen sich die Nullverteilungen deutlich schneller berechnen.\rEin Vergleich:\nlibrary(mosaic)\rlibrary(mosaicCore)\rsource(\u0026quot;https://raw.githubusercontent.com/NMarkgraf/FastSimNullDistR/master/R/fastSimNullDistRMean.R\u0026quot;)\rsource(\u0026quot;https://raw.githubusercontent.com/NMarkgraf/FastSimNullDistR/master/R/fastSimNullDistRProp.R\u0026quot;)\rsource(\u0026quot;https://raw.githubusercontent.com/NMarkgraf/FastSimNullDistR/master/R/fastSimNullDistR_work.R\u0026quot;)\rset.seed(2009)\rsystem.time(NullDistMosaic_aw \u0026lt;- do(10000) * diffprop(sex ~ shuffle(time), success = \u0026quot;Female\u0026quot;, data = tips))\r## User System verstrichen ## 10.81 0.00 10.83\rset.seed(2009)\rsystem.time(NullDistFSNDR_aw \u0026lt;- fastSimNullDistRProp(sex ~ time, success = \u0026quot;Female\u0026quot;, data = tips))\r## User System verstrichen ## 0.32 0.00 0.33\rset.seed(2009)\rsystem.time(NullDistMosaic_mw \u0026lt;- do(10000) * diffmean(total_bill ~ shuffle(time), data = tips))\r## User System verstrichen ## 10.76 0.00 10.76\rset.seed(2009)\rsystem.time(NullDistFSNDR_mw \u0026lt;- fastSimNullDistRMean(total_bill ~ time, data = tips))\r## User System verstrichen ## 0.33 0.00 0.33\rDas mit den beiden Routinen aus FastSimNullDistR die gleichen Ergebnisse zu erwarten sind, sie also ein “(quasi-)drop-in-replacements” der Mosaic Routinen darstellen, kann man an den folgenden QQ-Plots erkennen:\nqqplot(NullDistFSNDR_aw$diffprop, NullDistMosaic_aw$diffprop)\rqqplot(NullDistFSNDR_mw$diffmean, NullDistMosaic_mw$diffmean)\r\rWoher kommt die Geschwindigkeit?\rSchaut man sich den Quellcode von Mosaic an, wird einem schnell klar, dass es zwar didaktisch sinnvoll ist die unabhängige Variable mit shuffle() zu bearbeiten, nicht aber programmiertechnisch. Und wenn, dann nicht in dem man die ganze Datenzeile für die Berechnung kopiert. Statt also \\(10\\,000\\) mal die ganzen Daten im Speicher zu kopieren wäre es doch sinnvoll einen Index auf die unveränderten Daten indirekt über einen Index zuzugreifen. Und genau da liegt der Zugang der Routinen. Nur dieser Zugriffsindex wird geshuffelt und das spart Speicherplatz und Rechenzeit.\n\r","date":1525219200,"expirydate":-62135596800,"kind":"page","lang":"de","lastmod":1525219200,"objectID":"c6869bacc3c45d64cb37b202808cd0ad","permalink":"/nab/post/ein-wenig-schneller-zur-simulierten-nullverteilung/","publishdate":"2018-05-02T00:00:00Z","relpermalink":"/nab/post/ein-wenig-schneller-zur-simulierten-nullverteilung/","section":"post","summary":"Ein Nullhypothesentest ist schnell geschrieben.\rWill man den approximativen Weg gehen, so hilft R einem mit entsprechenden Tests mit einfachen Befehlen.\rNimmt man MOSAIC dazu, so bekommt man u.a. für den Test auf Anteils- oder Mittelwerte sogar einen sehr einfachen, weil einheitlichen, Syntax.\nZwei Beispiele für approximative Hypothesentests mit MOSAIC\rLaden wir unsere Testdaten, die tipping Daten wie folgt:\nlibrary(mosaic)\rdownload.file(\u0026quot;https://goo.gl/whKjnl\u0026quot;, destfile = \u0026quot;tips.csv\u0026quot;)\rtips \u0026lt;- read.csv2(\u0026quot;tips.csv\u0026quot;)\rset.seed(2009)\rDann erstellen wir zwei Forschungsfragen:","tags":["R","Lehre","Statistik"],"title":"Ein wenig schneller zur simulierten Nullverteilung","type":"post"},{"authors":null,"categories":["Statistik"],"content":"\rDer tipping Datensatz wird oft analysiert. Das Verhältnis von Trinkgeld (tip) und Rechnungsbetrag (total_bill) steht dabei im Vordergrund einer lineare Regressionsanalyse.\rSo auch hier. Wir wollen die einzelnen Angaben von R dabei in den Fokus rücken und einmal Hinterfragen, was wir bei der Ausgabe von R eigentlich genau sehen, woher es kommt und wie man es interpretieren kann.\nZunächst laden wir dazu die tipping Daten mittels\nlibrary(mosaic)\rdownload.file(\u0026quot;https://goo.gl/whKjnl\u0026quot;, destfile = \u0026quot;tips.csv\u0026quot;)\rtips \u0026lt;- read.csv2(\u0026quot;tips.csv\u0026quot;)\rin den Arbeitsspeicher.\nEine lineares Modell wird schnell mit\nlinMod \u0026lt;- lm(tip ~ total_bill, data = tips)\rerstellt.\rBetrachten wir die Zusammenfassung:\nsummary(linMod)\r## ## Call:\r## lm(formula = tip ~ total_bill, data = tips)\r## ## Residuals:\r## Min 1Q Median 3Q Max ## -3.1982 -0.5652 -0.0974 0.4863 3.7434 ## ## Coefficients:\r## Estimate Std. Error t value Pr(\u0026gt;|t|) ## (Intercept) 0.920270 0.159735 5.761 2.53e-08 ***\r## total_bill 0.105025 0.007365 14.260 \u0026lt; 2e-16 ***\r## ---\r## Signif. codes: 0 \u0026#39;***\u0026#39; 0.001 \u0026#39;**\u0026#39; 0.01 \u0026#39;*\u0026#39; 0.05 \u0026#39;.\u0026#39; 0.1 \u0026#39; \u0026#39; 1\r## ## Residual standard error: 1.022 on 242 degrees of freedom\r## Multiple R-squared: 0.4566, Adjusted R-squared: 0.4544 ## F-statistic: 203.4 on 1 and 242 DF, p-value: \u0026lt; 2.2e-16\rDie zentrale Frage bei einer linearen Regression ist, finden wir einen linearen Zusammenhang in unserer Stichprobe, den wir auf die Population (als die Grundgesamtheit) übertragen können.\nDie Spalte Estimate im Abschnitt Coefficients liefert uns in unser Stichprobe einen möglichen linearen Zusammenhang gemäß\n\\[\\hat{y}_{\\text{tip}} = \\hat{\\beta}_{\\text{0}} + \\hat{\\beta}_{\\text{total_bill}} \\cdot x_{\\text{total_bill}},\\]\nmit den Regressionskoeffizienten \\(\\hat{\\beta}_0=0.9202696\\) und \\(\\hat{\\beta}_{\\text{total_bill}}=0.1050245\\).\nGraphisch ergibt sich damit das Modell wie folgt:\n# Statt plotModel(linMod) besser:\rmypanel \u0026lt;- function(x, y) {\r# Scatterplot:\rpanel.xyplot(x, y, col = \u0026quot;darkgreen\u0026quot;) # Regressionsgerade:\rpanel.abline(linMod, col = \u0026quot;red\u0026quot;, lwd = 1.2, lty = 2)\r}\rxyplot(\rtip ~ total_bill, data = tips, panel = mypanel,\rmain = \u0026quot;Streudiagramm der Trinkgelder\u0026quot;,\rylab = \u0026quot;Trinkgeld\u0026quot;,\rxlab = \u0026quot;Rechnungsbetrag\u0026quot;,\rkey = list(\rspace = \u0026quot;bottom\u0026quot;, padding.text = 8,\rlines = list(col = c(\u0026quot;red\u0026quot;), lty = c(2), lwd = 1.2),\rtext = list(c(\u0026quot;Regressionsgerade\u0026quot;))\r)\r)\rWas hat es mit dem y-Achsenabschnitt \\(\\hat{\\beta}_0\\) auf sich?\nIst es etwa eine Art Grundtrinkgeld, mit dem der Kellern rechnen kann, auch wenn der Kunde gar nichts bestellt?\nNun ja, es so etwas in der Art, aber eben ein rein fiktiver Wert, der durch die Konstruktion der Parameter entsteht.\rEine (affin-)lineare Gerade geht nun einmal irgendwann durch die y-Achse (wenn sie nicht parallel dazu ist) und es kann passieren, dass eine sinnvolle Interpretation nicht so ohne weiteres möglich ist.\nWir können aber dieses Grundtrinkgeld heraus nehmen und den y-Achsenabschnitt auf Null setzen. Dazu ziehen wir \\(\\hat{\\beta}_0\\) einfach von alle Trinkgeldern ab. Wir erhalten quasi nur noch den Trinkgeldzuwach.\nbeta_0 \u0026lt;- coef(linMod)[\u0026quot;(Intercept)\u0026quot;] # Grundtrinkgeld\rtips$delta_tip \u0026lt;- tips$tip - beta_0 # wird abgezogen\rVergleichen wir das alte lineare Modell mit dem neuen Modell (linModDelta):\nlinModDelta \u0026lt;- lm(delta_tip ~ total_bill, data = tips)\rsummary(linModDelta)\r## ## Call:\r## lm(formula = delta_tip ~ total_bill, data = tips)\r## ## Residuals:\r## Min 1Q Median 3Q Max ## -3.1982 -0.5652 -0.0974 0.4863 3.7434 ## ## Coefficients:\r## Estimate Std. Error t value Pr(\u0026gt;|t|) ## (Intercept) -4.549e-15 1.597e-01 0.00 1 ## total_bill 1.050e-01 7.365e-03 14.26 \u0026lt;2e-16 ***\r## ---\r## Signif. codes: 0 \u0026#39;***\u0026#39; 0.001 \u0026#39;**\u0026#39; 0.01 \u0026#39;*\u0026#39; 0.05 \u0026#39;.\u0026#39; 0.1 \u0026#39; \u0026#39; 1\r## ## Residual standard error: 1.022 on 242 degrees of freedom\r## Multiple R-squared: 0.4566, Adjusted R-squared: 0.4544 ## F-statistic: 203.4 on 1 and 242 DF, p-value: \u0026lt; 2.2e-16\rIn diesem Modell ist der Wert für den y-Achsenabschnitt numerisch gleich 0. – Ja, da mag zwar \\(-4.5487837\\times 10^{-15}\\) stehen, jedoch sind so kleine Werte der jedem Rechner inne wohnenden Ungenauigkeit in der Gleitkomma-Arithmetik geschuldet und ist faktisch gleich 0.\nDer Wert für die Steigung lautet weiterhin \\(0.1050245\\).\rDas war auch zu erwarten, denn wir haben unsere Regressionsgerade eigentlich nur um \\(\\hat{\\beta}_0\\) nach unten verschoben. (Der Fachmann spricht von einer Translation (Parallelverschiebung)1 um \\(-\\hat{\\beta}_0\\).\n# Statt plotModel(linModDelta) besser:\rmypanel \u0026lt;- function(x, y) {\r# Scatterplot:\rpanel.xyplot(x, y, col = \u0026quot;darkgreen\u0026quot;) # Regressionsgerade:\rpanel.abline(linModDelta, col = \u0026quot;red\u0026quot;, lwd = 1.2, lty = 2)\r}\rxyplot(\rdelta_tip ~ total_bill, data=tips, panel = mypanel,\rmain = \u0026quot;Streudiagramm der Delta Trinkgelder\u0026quot;,\rylab = \u0026quot;Delta Trinkgeld\u0026quot;,\rxlab = \u0026quot;Rechnungsbetrag\u0026quot;,\rkey = list(\rspace=\u0026quot;bottom\u0026quot;, padding.text=8,\rlines=list(col=c(\u0026quot;red\u0026quot;), lty=c(2), lwd=1.2),\rtext=list(c(\u0026quot;Regressionsgerade\u0026quot;)))\r)\rVergleichen wir die beiden Zusammenfassungen, so stellen wir fest das sich mit Ausnahme der [Intercept] Zeile praktisch nichts geändert hat. Das ist kein Wunder, sondern Absicht!\nDie Regressionsgerade stellt für unsere Stichprobe die Gerade mit dem geringsten Fehler an den Datenpunkten dar. Mathematisch heißt das folgendes:\nAn den \\(n=244\\) Datenpunkten unserer Stichprobe \\((x_i, y_i)=(tips\\$total\\_bill[i], tips\\$tip[i])\\) [für \\((i=1, \\dots, n)\\)] sind die Residuen, also die Fehlerterme,\n\\[\r\\hat{e}_i =\\hat{y}_i - y_i = \\left[\\hat{\\beta}_{\\text{0}} + \\hat{\\beta}_{\\text{total_bill}} \\cdot x_i\\right] - y_i\r\\]\ndurch die verwendete Methode der kleinsten Quadrate2 quadratisch minimal. Kurz:\n\\[\r\\sum_{i=1}^n (\\hat{e}_i)^2 \\text{ ist minimal!}\r\\]\nWir können diese Fehlerterme graphisch ansehen um die Varianz der Residuen zu sehen.\rDazu ziehen wir von allen Datenpunkten \\(y_i\\) den geschätzten Wert \\(\\hat{y}_i\\) ab und erstellen ein neues lineares Modell:\nbeta_total_bill \u0026lt;- coef(linModDelta)[\u0026quot;total_bill\u0026quot;]\rtips$error_tip \u0026lt;- (tips$tip - beta_0 - beta_total_bill * tips$total_bill)\rlinModError \u0026lt;- lm(error_tip ~ total_bill, data = tips)\rsummary(linModError)\r## ## Call:\r## lm(formula = error_tip ~ total_bill, data = tips)\r## ## Residuals:\r## Min 1Q Median 3Q Max ## -3.1982 -0.5652 -0.0974 0.4863 3.7434 ## ## Coefficients:\r## Estimate Std. Error t value Pr(\u0026gt;|t|)\r## (Intercept) 1.900e-15 1.597e-01 0 1\r## total_bill -8.740e-17 7.365e-03 0 1\r## ## Residual standard error: 1.022 on 242 degrees of freedom\r## Multiple R-squared: 6.665e-31, Adjusted R-squared: -0.004132 ## F-statistic: 1.613e-28 on 1 and 242 DF, p-value: 1\rAlso Diagramm sieht es dann so aus:\n# Statt plotModel(linModError) besser:\rmypanel \u0026lt;- function(x, y) {\r# Scatterplot:\rpanel.xyplot(x, y, col = \u0026quot;darkgreen\u0026quot;) # Regressionsgerade:\rpanel.abline(linModError, col = \u0026quot;red\u0026quot;, lwd = 1.2, lty = 2)\r}\rxyplot(\rerror_tip ~ total_bill, data = tips, panel = mypanel,\rmain = \u0026quot;Streudiagramm der Residuen\u0026quot;,\rylab = \u0026quot;Residuen\u0026quot;,\rxlab = \u0026quot;Rechnungsbetrag\u0026quot;,\rkey = list(\rspace = \u0026quot;bottom\u0026quot;, rows = 3, padding.text = 8,\rlines = list(col=c(\u0026quot;red\u0026quot;), lty = c(2), lwd = 1.2),\rtext = list(c(\u0026quot;Regressionsgerade / x-Achse\u0026quot;))\r)\r)\rWir können die Graphik im wesentlichen auch einfacher über den Befehl\nxyplot(residuals(linMod) ~ fitted(linMod))\rerhalten.\nBetrachten wir kurz nur die Residuen:\nfavstats(~residuals(linMod))\r## min Q1 median Q3 max mean\r## -3.198225 -0.5651615 -0.09744499 0.4863111 3.743435 -2.022281e-17\r## sd n missing\r## 1.019943 244 0\rWir sehe, dass wir in der Zusammenfassung immer genau diese Werte unter dem Abschnitt Residuals gefunden haben. Minimum, das 1. Quantil, der Median, das 3. Quantil und das Maximum stimmen überein.\nDer erwartungstreue und unverzerrte Schätzer für den Standardfehler der Residuen, lautet\n\\[\r\\begin{align*}\rSE_{\\text{Residuen}} \u0026amp;= \\sqrt{\\frac{1}{n-2} \\cdot \\sum_{i=1}^n (\\hat{e_i})^2} = \\sqrt{\\frac{n-1}{n-2} \\cdot \\frac{1}{n-1} \\cdot \\sum_{i=1}^n (\\hat{e_i})^2} \\\\\r\u0026amp;= \\sqrt{\\frac{n-1}{n-2}} \\cdot \\sqrt{\\frac{1}{n-1} \\cdot \\sum_{i=1}^n (\\hat{e_i})^2} \\\\\r\u0026amp;= \\sqrt{\\frac{n-1}{n-2}} \\cdot s_{\\text{Residuen}}\r\\end{align*}\r\\]\nAlso finden wir den Wert Residual standard error aus der Zeile\n## Residual standard error: 1.022 on 242 degrees of freedom\rin dem wir den in den favstats gefundenen Wert für die Standardabweichung entsprechen korrigieren:\n\\[\rSE_{\\text{Residuen}} = \\sqrt{\\frac{n-1}{n-2}} \\cdot s_{\\text{Residuen}} = \\sqrt{\\frac{243}{242}} \\cdot 1.0199426 = 1.0220477\r\\]\nDer Median der Residuen ist nicht gleich Null, wie der Mittelwert. (Welcher auch hier als numerisch Null interpretiert werden muss!)\rEs könnte also eine linkssteile, rechtsschiefe Verteilung der Residuen vorliegen.\rBetrachten wir dazu das Histogramm:\nhistogram(~residuals(linMod), nint = 19)\rSchon beim ersten Blick auf das Histogramm kann an eine Normalverteilung der Residuen nicht mehr so ganz geglaubt werden.\nEin Shapiro-Wilk-Test3 hat als Nullhypothese die Annahme, dass die Daten normalverteilt sind!\nshapiro.test(residuals(linMod))\r## ## Shapiro-Wilk normality test\r## ## data: residuals(linMod)\r## W = 0.96728, p-value = 2.171e-05\rDavon ist nach dem Ergebnis eben sowenig auszugehen, wie nach einem Blick auf das QQ-Normal-Diagramm:\nqqnorm(residuals(linMod), col = \u0026quot;darkgreen\u0026quot;)\rEin K.O.-Kriterium für gute Prognosen.\nWie gut aber beschreibt unsere Regressionsgerade die Daten?\nAls Maß dafür können wir das Bestimmtheitsmaß nehmen.\nEin kurzer Blick auf die Situation, der Mittelwert der Trinkgelder ist\n\\[\r\\bar{y} = \\frac{1}{n} \\cdot \\sum_{i=1}^n y_i = 2.9982787.\r\\]\nWir erhalten so folgendes Diagramm:\nmypanel \u0026lt;- function(x, y) {\rpanel.xyplot(x, y)\rpanel.abline(h = mean(y), lwd = 1.2, lty = 2, col = \u0026quot;darkgreen\u0026quot;)\rpanel.lmline(x, y, col = \u0026quot;red\u0026quot;, lwd = 1.2, lty = 2)\r}\rxyplot(\rtip ~ total_bill, data = tips, panel = mypanel,\rmain = \u0026quot;Streudiagramm der Trinkgelder\u0026quot;,\rylab = \u0026quot;Trinkgeld\u0026quot;,\rxlab = \u0026quot;Rechnungsbetrag\u0026quot;,\rkey = list(\rspace = \u0026quot;bottom\u0026quot;,\rpadding.text = 8,\rcolumns = 2,\rjust = c(\u0026quot;center\u0026quot;, \u0026quot;bottom\u0026quot;),\rlines = list(col = c(\u0026quot;darkgreen\u0026quot;, \u0026quot;red\u0026quot;), lty = c(2, 2), lwd = 1.2),\rtext = list(c(expression(bar(y)), expression(hat(beta)[0]+hat(beta)[total_bill] * x[total_bill]))),\rtext = list(c(\u0026quot;Mittelwert Trinkgeld\u0026quot;, \u0026quot;Regressionsgerade\u0026quot;))\r)\r)\rDie Varianz \\(s^2_{y_i}=1.9144546\\) beschreibt die mittlere quadratische Abweichung der Datenpunkte \\(y_i\\) vom Mittelwert \\(\\bar{y}\\).\rDiese Varianz lässt sich Zerlegen in einen Anteil, der durch die Regressionsgerade erklärt wird und in einen Anteil, der durch die Regressionsgerade nicht erklärt wird.\n\\[\rs^2_{y_i} = s^2_{\\hat{y}_i} + s^2_{\\hat{e}_i}\r\\]\rDividiert man beider Seiten durch die Varianz \\(s^2_{y_i}\\), so normiert man den Ausdruck und kann den Faktor \\(\\frac{1}{n-1}\\) (bzw. \\(\\frac{1}{n}\\)) herauskürzen. Es bleibt dann:\n\\[\r1 = \\frac{\\sum_{i=1}^n (\\bar{y}- \\hat{y_i})^2}{\\sum_{i=1}^n (\\bar{y}-y_i)^2} + \\frac{\\sum_{i=1}^n (\\hat{e_i})^2}{\\sum_{i=1}^n (\\bar{y}-y_i)^2}\r\\]\nMultipliziert man beide Seiten mit \\(\\sum_{i=1}^n (y_i)^2\\), so erhält man:\n\\[\r\\sum_{i=1}^n (\\bar{y}- y_i)^2 = \\sum_{i=1}^n (\\bar{y}- \\hat{y_i})^2+ \\sum_{i=1}^n (\\hat{e_i})^2 \\]\nZur Vereinfachung nennt man die einzelnen Summen in dem Ausdruck wie folgt:\n\rDer erste Ausdruck heißt Gesamtvarianz oder total sum of squares oder kurz \\(SS_T\\), (oder TSS) er ist die Summe der quadrierten Differenzen\r\r\\[\rSS_T = \\sum_{i=1}^n (\\bar{y}-y_i)^2\r\\]\n\rDer zweite Ausdruck heißt Modellvarianz oder model sum of squares oder kurz \\(SS_M\\) (oder RSS), er ist die Summe der quadrierten Differenzen aus dem Mittelwert \\(\\bar{y}\\) und der Punkte auf der Regressionsgeraden \\(\\hat{y}_i\\):\r\r\\[\rSS_M = \\sum_{i=1}^n (\\bar{y}-\\hat{y}_i)^2\r\\]\n\rDer dritte Ausdruck heißt Gesamt-Verhersage-Fehler, Fehlersteuung der Regression oder error sum of squares oder kurz \\(SS_E\\) (oder ESS), er ist die Summe der quadratischen Differenz aus den Datenpunkten \\(y_i\\) und den Punkten der Regressionsgeraden \\(\\hat{y}_i\\):\r\r\\[\rSS_E = \\sum_{i=1}^n (\\hat{y}_i-y_i)^2 = \\sum_{i=1}^n (\\hat{e}_i)^2\r\\]\nWir können daher auch kurz\n\\[\rSS_T = SS_M + SS_E\r\\]\rschreiben und sparen uns die ganzen Summenzeichen.\nDie Güte einer Regression wollen wir durch den Anteil der durch das Model erklärten Varianz (also der \\(SS_M\\)) ausdrücken und stellen daher nach \\(SS_M\\) um:\n\\[\rSS_M = SS_T - SS_E\r\\]\rTeilen wir beide Seiten durch \\(SS_T\\) also der maximalen (weil totalen) Quadratsumme, so erhalten wir:\r\\[\r\\frac{SS_M}{SS_T} = \\frac{SS_T}{SS_T} - \\frac{SS_E}{SS_T} = 1 - \\frac{SS_E}{SS_T}\r\\]\nDen Ausdruck \\(\\frac{SS_M}{SS_T}\\) nennen wir Bestimmtheitsmaß und schreiben dafür \\(R^2\\). Es ist ein Wert zwischen 0 und 1, der den Anteil der durch das Modell beschriebenen Varianz in Bezug auf die Gesamtvarianz angibt. Kraft Definition ist \\(R^2\\) im eindimensionalen Fall tatsächlich das Quadrat des (Pearson-)Korrelationskoeffizienten \\(r\\). (M.a.W.: \\(R^2= r^2\\).)\nIn unserer Zusammenfassung des linearen Models findet sich dieser Wert auch. Und zwar unter dem Begriff:\n## Multiple R-squared: 0.4566, \rEs gilt ja:\n\\[\rR^2 = 1 - \\frac{SS_E}{SS_T} = 1 - \\frac{s^2_{\\hat{e}_i}}{s^2_{y_i}} = 1 - \\frac{1.0402829}{1.9144546} = 0.4566166\r\\]\nDer Wert\n## ..., Adjusted R-squared: 0.4544\rerklärt sich daraus4, dass das Bestimmheitsmaß um so größer wird je größer die Zahl der unabhängigen Variablen wird.\rUnd zwar unabhöngig davon, ob weitere unabhängige Variablen wirklich einen Beitrag zur Erklärungskraft liefern.\rDaher nutzt man besser das korrigierte Bestimmtheitsmaß (engl.: adjusted R-squared) \\(\\bar{R}^2\\):\n\\[\r\\begin{align*}\r\\bar{R}^2 \u0026amp;= 1- (1-R^2) \\cdot \\frac{n-1}{n-p-1}\\\\ \u0026amp;= R^2 - (1-R^2) \\cdot \\frac{p}{n-p-1}\r\\end{align*}\r\\]\nWobei \\(p\\) die Anzahl der unabhängigen Variablen im Modell darstellt.\rIn unserem Beispiel gilt daher:\n\\[\r\\begin{align*}\r\\bar{R}^2 \u0026amp;= 1 - (1-R^2) \\cdot \\frac{n-1}{n-p-1} \\\\\r\u0026amp;= 1 - (1- 0.4566166) \\cdot \\frac{244-1}{244- 1- 1} \\\\\r\u0026amp;= 0.4543712\r\\end{align*}\r\\]\nVorsicht: Das korrigierte Bestimmtheitsmaß ist nicht mehr an das Intervall \\([0; 1]\\) gebunden!\rEs kann negative Werte annehmen, ist in der Regel kleiner als das (unkorrigierte) Bestimmtheitsmaß und erreicht die obere Grenze (\\(\\bar{R}^2=1\\)) genau dann, wenn \\(R^2 = 1\\) ist.\nBei der Gesamtsignifikanz des Modells (auch Overall-F-Test genannt) wird geprüft, ob mindestens eine Variable einen Erklärungsgehalt für das Modell liefert.\nFalls diese Hypothese verworfen wird ist somit das Modell nutzlos.\rDieser Test lässt sich so interpretieren als würde man die gesamte Güte des Modells, also das \\(R^2\\) des Modells, testen.\rAus diesem Grund wird der F-Test der Gesamtsignifikanz des Modells auch als Anpassungsgüte-Test bezeichnet.\rDie Nullhypothese des F-Test der Gesamtsignifikanz des Modells sagt aus, dass alle erklärenden Variablen keinen Einfluss auf die abhängige Variable haben.\rSowohl die abhängige Variable als auch die unabhängigen Variablen können binär (kategoriell) oder metrisch sein.\rDer Wald-Test kann dann die Hypothesen testen (ohne Einbezug des Achsenabschnittes):\n\\[\rH_{0}\\colon \\beta _{1}=\\beta _{2}=\\ldots =\\beta _{k}\\;=\\;0\\Rightarrow R^{2}=0\r\\]\rgegen\n\\[\rH_{1}:\\beta _{j}\\;\\neq \\;0\\;\\mathrm {f{\\ddot {u}}r\\;mindestens\\;ein} \\;j\\in \\{1,\\ldots ,k\\}\\Rightarrow R^{2}\\neq 0\r\\]\nDie Teststatistik dieses Tests lautet\n\\[\r\\begin{aligned}\rF\\;\\;{\\stackrel {H_{0}}{=}}{\\frac {R^{2}}{1-R^{2}}} \\cdot {\\frac {n-p-1}{p}}\\;\\;{\\stackrel {H_{0}}{\\sim }}\\;\\;F(p,n-p)\r\\end{aligned}.\r\\]\nmit \\(p\\) und \\(\\displaystyle (n-p-1)\\) Freiheitsgraden.\rÜberschreitet der empirische F-Wert einen kritischen F-Wert, der zu einem a priori festgelegten Signifikanzniveau \\(\\alpha\\), so verwirft man die Nullhypothese \\(H_{0}\\).\rDas \\(R^{2}\\) ist dann ausreichend groß und mindestens ein Regressor trägt also vermutlich genügend viel Information zur Erklärung von \\(y\\) bei.\rEs ist naheliegend bei hohen F-Werten die Nullhypothese zu verwerfen, da ein hohes Bestimmtheitsmaß zu einem hohen F-Wert führt.\rWenn der Wald-Test für eine oder mehrere unabhängige Variablen die Nullhypothese ablehnt, dann kann man davon ausgehen, dass die zugehörigen Parameter ungleich Null sind, so dass die Variable(n) in das Modell mit einbezogen werden sollten.\nIn unserem Beispiel ist\n\\[\rF={\\frac {R^{2}}{1-R^{2}}} \\cdot {\\frac {n-p-1}{p}} = \\frac{0.4566166}{1-0.4566166} \\cdot \\frac{244-1-1}{1} = 203.3577233\r\\]\nder Wert in der Zeile\n## F-statistic: 203.4 on 1 and 242 DF, p-value: \u0026lt; 2.2e-16\rmit Parametern \\(p=1\\) und \\(n-p-1=242\\) Freiheitsgraden.\nDer p-Wert von (numerisch) 0, liefert also ein hinreichendes Indiz dafür, dass der Rechnungsbetrag einen echten Beitrag liefert.\n\rvgl.: https://de.wikipedia.org/wiki/Parallelverschiebung↩\n\rvgl.: https://de.wikipedia.org/wiki/Methode_der_kleinsten_Quadrate↩\n\rvgl.: https://de.wikipedia.org/wiki/Shapiro-Wilk-Test↩\n\rvgl.: https://de.wikipedia.org/wiki/Bestimmtheitsmaß#Das_korrigierte_Bestimmtheitsmaß↩\n\r\r\r","date":1515369600,"expirydate":-62135596800,"kind":"page","lang":"de","lastmod":1515369600,"objectID":"48e135650b75599cf307d91b5d94b8e0","permalink":"/nab/post/nur-ein-wenig-lineare-regression/","publishdate":"2018-01-08T00:00:00Z","relpermalink":"/nab/post/nur-ein-wenig-lineare-regression/","section":"post","summary":"Der tipping Datensatz wird oft analysiert. Das Verhältnis von Trinkgeld (tip) und Rechnungsbetrag (total_bill) steht dabei im Vordergrund einer lineare Regressionsanalyse.\rSo auch hier. Wir wollen die einzelnen Angaben von R dabei in den Fokus rücken und einmal Hinterfragen, was wir bei der Ausgabe von R eigentlich genau sehen, woher es kommt und wie man es interpretieren kann.\nZunächst laden wir dazu die tipping Daten mittels\nlibrary(mosaic)\rdownload.file(\u0026quot;https://goo.gl/whKjnl\u0026quot;, destfile = \u0026quot;tips.","tags":["Lehre","R","Statistik"],"title":"Nur ein wenig lineare Regression","type":"post"},{"authors":null,"categories":["Statistik"],"content":"\r*WORK IN PROGRESS\rDieser Eintrag ist noch nicht fertig und wird in der Zukunft erweitert!\nKonfidenzintervalle\rDefinition von Konfidenzintervallen1\rFür unabhängig identisch verteilte Zufallsvariablen \\(X_1,\\dotsc, X_n\\) mit unbekanntem reellen Verteilungsparameter \\(\\vartheta\\) kann unter bestimmten Umständen zwei Stichprobenfunktionen \\(U\\) und \\(V\\) angeben, so dass\n\\[P(U \u0026lt; \\vartheta \u0026lt; V) \\geq \\gamma\\]\ngilt, mit \\(\\gamma \\in (0,1)\\).\rDann heißt das (stochastische) Intervall \\([U, V]\\) ein Konfidenzintervall für \\(\\vartheta\\) zum Konfidenzniveau \\(\\gamma\\) (auch: ein \\(\\gamma\\)-Konfidenzintervall).\nDie Realisationen \\(u\\) und \\(v\\) von \\(U\\) bzw. \\(V\\) bilden das Schätzintervall \\([u, v]\\).\nDa die Realisationen \\(u\\) und \\(v\\) der Grenzen \\(U\\) und \\(V\\) keine Zufallsvariablen sind und \\(\\vartheta\\) ein fixer Wert ist, kann man nicht sagen, dass das Schätzintervall \\([u, v]\\) mit einer Wahrscheinlichkeit von \\(\\gamma\\) den unbekannten Parameter \\(\\vartheta\\) enthält. Es bedeutet vielmehr, dass im Mittel ein Anteil von \\(\\gamma\\) aller so berechneten Schätzintervalle den unbekannten Parameter überdecken. Dem nicht widersprechend, kann –- wie bereits von Ronald Fisher festgestellt – in manchen Modellen die Qualität des Schätzintervalls von den Daten abhängen und sogar zu Antworten führen, die mit Blick auf die Daten unsinnig sind. Probleme mit solcher Post-Data-Inkohärenz führen zur Theorie der bedingten Inferenz. Ein weiteres Problem sind die Stichprobenfunktionen U und V an sich. Um diese zu finden werden oft Vereinfachungen getroffen, dadurch können systematische Fehler entstehen, oft es gibt mehrere Konfidenzintervalle (bei der Binomialverteilung z.B. nach Clopper-Pearson, Agresti-Coull oder Wald), welche oft unterschiedliche Werte liefern.\n\rEin Beispiel\rWir nehmen zunächst als Population \\(N=1000\\) normalverteilte Zufallszahlen mit dem Mittelwert \\(\\mu= 0\\) und der Standardabweichung \\(\\sigma=2.0088\\).\nDazu das Histogramm der Population:\nhistogram(pop, xlab=\u0026quot;Population\u0026quot;)\rAus dieser Population ziehen wir eine Stichprobe \\(x\\) vom Umfang $n=$40 und erhalten die folgenden statistischen Daten:\nfavstats(x)\r## min Q1 median Q3 max mean sd n missing\r## -4.997 -1.052 -0.3928 0.8211 3.295 -0.3423 1.878 40 0\rWir wollen nun den wahren Mittelwert \\(\\vartheta=\\mu\\) mit Hilfe der Stichprobe \\(x\\) schätzen. So ist es ja in der Realität auch, denn normalerweise haben wir die Daten über die Population nicht.\nDie Schätzfunktion für den Mittelwert lautet nun\r\\[\\bar{X} = \\frac1n \\sum_{i=1}^n X_i\\],\rund damit die konkrete Punktschätzung\r\\[\\hat{\\mu}=\\bar{x}= \\sum_{i=1}^n x_i\\]\rliefert den Wert \\(\\hat{\\mu}=\\) -0.3423.\nIn unserem Beispiel unterscheiden sich die beiden Werte um \\(\\mu - \\hat{\\mu}=\\) 0.3423.\nEin 95%-Konfidenzintervall nimmt nun den geschätzen Wert \\(\\hat{\\mu}\\) als Grundlage und gibt liefert ein Intervall mit der Eigentschaft, ausgehend von den konkreten Stichproben in 95% der Fälle den tatsächlichen Wert \\(\\mu\\) zu umfassen. Es ist also\r\\[\\gamma = 0.95 = 1 - \\alpha = 1 - 0.05, \\quad \\alpha = 0.05\\]\nDazu werden die beiden Stichprobenfunktionen\n\\[U=U(X_1, \\dots, X_n)=\\bar{X}-z_{\\left(1-\\frac{\\alpha}{2}\\right)}\\cdot\\frac{\\sigma}{\\sqrt{n}}\\]\nund\n\\[V=V(X_1, \\dots, X_n)=\\bar{X}-z_{\\left(1-\\frac{\\alpha}{2}\\right)}\\cdot\\frac{\\sigma}{\\sqrt{n}}\\]\nmit der bekannten Standardabweichung \\(\\sigma\\) der Population und der Stichprobengröße \\(n\\) nun mit der konkreten Realisation \\(x_1, \\dots, x_n\\) der Stichprobe gefüttert und wir erhalten damit\n\\[u = \\bar{x}-z_{\\left(1-\\frac{\\alpha}{2}\\right)}\\cdot\\frac{\\sigma}{\\sqrt{n}} = -0.3423-z_{\\left(0.975\\right)}\\cdot\\frac{2.0088}{\\sqrt{40}}=-0.9648\\]\rund\n\\[v = \\bar{x}+z_{\\left(1-\\frac{\\alpha}{2}\\right)}\\cdot\\frac{\\sigma}{\\sqrt{n}} = -0.3423+z_{\\left(0.975\\right)}\\cdot\\frac{2.0088}{\\sqrt{40}}=0.2803.\\]\nDie Realisation unseres 95%-Konfidenzintervall lautet nun also:\n\\[[-0.9648; 0.2803]\\]\nWas hat es nun mit den ominösen 95% auf sich?\nDas Konfidenzintervall ist ein stochastisches Intervall, d.h. die hier angegebenen Werte für \\(u\\) und \\(v\\) sind abhängig von der Realisation \\(x_1, \\dots, x_n\\), also der konkreten Stichprobe.\nNehmen wir nun also einmal eine neue Stichprobe und berechnen erneut die Realisation unseres 95%-Konfidenzintervalls, so erhalten wir:\n\\[[-0.8459; 0.3992]\\]\n## Interval coverage:\r## cover\r## n Low Yes High\r## 40 0.03 0.95 0.02\r\r\rPrognoseintervalle\r\rFuduzialintervalle\rQuellen:\n\rLogik in der Statistik; Andrea Wiencierz, 7.10.2007 Link: https://static.aminer.org/pdf/PDF/000/230/772/induktive_inferenz_und_mehrwertige_logik.pdf\r\r\r\rvgl: https://de.wikipedia.org/wiki/Konfidenzintervall↩\n\r\r\r","date":1515024000,"expirydate":-62135596800,"kind":"page","lang":"de","lastmod":1515024000,"objectID":"dc11f88cf1f1c3c8afcf39671770af10","permalink":"/nab/post/prognose-konfidenz-und-fiduzialintervalle/","publishdate":"2018-01-04T00:00:00Z","relpermalink":"/nab/post/prognose-konfidenz-und-fiduzialintervalle/","section":"post","summary":"*WORK IN PROGRESS\rDieser Eintrag ist noch nicht fertig und wird in der Zukunft erweitert!\nKonfidenzintervalle\rDefinition von Konfidenzintervallen1\rFür unabhängig identisch verteilte Zufallsvariablen \\(X_1,\\dotsc, X_n\\) mit unbekanntem reellen Verteilungsparameter \\(\\vartheta\\) kann unter bestimmten Umständen zwei Stichprobenfunktionen \\(U\\) und \\(V\\) angeben, so dass\n\\[P(U \u0026lt; \\vartheta \u0026lt; V) \\geq \\gamma\\]\ngilt, mit \\(\\gamma \\in (0,1)\\).\rDann heißt das (stochastische) Intervall \\([U, V]\\) ein Konfidenzintervall für \\(\\vartheta\\) zum Konfidenzniveau \\(\\gamma\\) (auch: ein \\(\\gamma\\)-Konfidenzintervall).","tags":["Statistik","Lehre"],"title":"Prognose-, Konfidenz- und Fiduzialintervalle","type":"post"},{"authors":null,"categories":["Statistik"],"content":"\r\n\r\n\r\n\r\n","date":1514764800,"expirydate":-62135596800,"kind":"page","lang":"de","lastmod":1514764800,"objectID":"d2da72d226f2874cb281cbe11f074661","permalink":"/nab/post/konfidenzintervalle/","publishdate":"2018-01-01T00:00:00Z","relpermalink":"/nab/post/konfidenzintervalle/","section":"post","summary":"","tags":["Lehre","Statistik","Wahrscheinlichkeitstheorie"],"title":"Konfidenzintervalle","type":"post"},{"authors":null,"categories":["Statistik"],"content":"\rDas zentrale Schwankungsintervall sagt etwas über die Präzision der Lageschätzung eines Parameters (zum Beispiel eines Mittelwertes) aus. Das Schwankungsintervall schließt einen Bereich um den wahren Wert des Parameters in der Grundgesamtheit ein, der – vereinfacht gesprochen – mit einer zuvor festgelegten Sicherheitswahrscheinlichkeit den aus der Stichprobe geschätzten Parameter enthält.1\n\rvgl: https://de.wikipedia.org/wiki/Zentrales_Schwankungsintervall↩\n\r\r\r","date":1514764800,"expirydate":-62135596800,"kind":"page","lang":"de","lastmod":1514764800,"objectID":"0cef821e93903fae276ebef421a3f5d4","permalink":"/nab/post/zentrales-schwankungsintervall/","publishdate":"2018-01-01T00:00:00Z","relpermalink":"/nab/post/zentrales-schwankungsintervall/","section":"post","summary":"\rDas zentrale Schwankungsintervall sagt etwas über die Präzision der Lageschätzung eines Parameters (zum Beispiel eines Mittelwertes) aus. Das Schwankungsintervall schließt einen Bereich um den wahren Wert des Parameters in der Grundgesamtheit ein, der – vereinfacht gesprochen – mit einer zuvor festgelegten Sicherheitswahrscheinlichkeit den aus der Stichprobe geschätzten Parameter enthält.1\n\rvgl: https://de.wikipedia.org/wiki/Zentrales_Schwankungsintervall↩\n\r\r\r","tags":["Lehre","Statistik","Wahrscheinlichkeitstheorie"],"title":"Zentrales Schwankungsintervall","type":"post"},{"authors":null,"categories":["Allgemeines"],"content":"Im Laufe der Zeit sammeln sich bei mir mehr und mehr Links zu anderen Seiten an, die ich irgendwie speichern will aber nicht ernsthaft sortieren möchte. So ist diese Sammlung hier entstanden:\n Blog von Prof. Dr. Timm Grams \u0026ndash; \u0026ldquo;Ein Weblogbuch über sonderbare Nachrichten und alltäglichen Statistikplunder\u0026rdquo;\n Denkfallen und Paradoxa \u0026ndash; Prof. Dr. Timm Grams gibt einen Überblick\n Signifikanztest mit der Vierfeldertafel \u0026ndash; Prof. Dr. Timm Grams\n Querbeet \u0026ndash; Eine Problemsammlung \u0026ndash; Prof. Dr. Timm Grams\n Blog von Prof. Dr. Sebastian Sauer \u0026ndash; Quelle der Erleuchtung und Intuition\n Six Sigma Material \u0026ndash; Six Sigma Seite\n AG Method(olgo)ische Grundlagen der Statistik und Ihre Anwendung \u0026ndash; LMU München \u0026hellip; WOW!\n Leseprobe \u0026ldquo;Induktive Statistik und soziologische Theorie\u0026rdquo; \u0026ndash; Markus Ziegler - Eine Analyse des theoretischen Potenzials der Bayes-Statistik\n Fiduzial \u0026ndash;\n Vorsicht bei der σ-Regel \u0026ndash; Stefan Bartz\n  ","date":1514678400,"expirydate":-62135596800,"kind":"page","lang":"de","lastmod":1514678400,"objectID":"434a6087f41ca5cdba40903421d1adf6","permalink":"/nab/post/ein-paar-interessante-links/","publishdate":"2017-12-31T00:00:00Z","relpermalink":"/nab/post/ein-paar-interessante-links/","section":"post","summary":"Im Laufe der Zeit sammeln sich bei mir mehr und mehr Links zu anderen Seiten an, die ich irgendwie speichern will aber nicht ernsthaft sortieren möchte. So ist diese Sammlung hier entstanden:\n Blog von Prof. Dr. Timm Grams \u0026ndash; \u0026ldquo;Ein Weblogbuch über sonderbare Nachrichten und alltäglichen Statistikplunder\u0026rdquo;\n Denkfallen und Paradoxa \u0026ndash; Prof. Dr. Timm Grams gibt einen Überblick\n Signifikanztest mit der Vierfeldertafel \u0026ndash; Prof. Dr. Timm Grams","tags":[],"title":"Ein paar interessante Links","type":"post"},{"authors":null,"categories":[],"content":"\r“Was hat das eigentlich mit den Quartilen, Quantilen und so weiter auf sich?” Diese Frage kommt ab und zu in Vorlesungen zur Statistik vor. Dabei ist die Antwort recht einfach.\nQuantile\rDefinitorische Antwort\rFür eine gegebene reelle Zufallsvariable \\(X\\) heißt eine reelle Zahl \\(x_p\\) ein p-Quantil (von \\(X\\)), falls gilt:\n\\[P(X \\leq x_p) \\leq p \\quad \\text{ und }\\quad P(x_p \\leq X) \\geq 1-p.\\]\n\rWas bedeutet das denn nun konkret?\rNun, ein Quantil ist ein Schwellenwert. Ein bestimmter Anteil der Werte ist kleiner als das Quantil, der Rest ist größer. Das 25-%-Quantil beispielsweise ist der Wert, für den gilt, dass 25 % aller Werte kleiner sind als dieser Wert. Quantile formalisieren praktische Aussagen wie „25 % aller Frauen sind kleiner als 1,62 m“ –- wobei 1,62 m hier das 25-%-Quantil ist.\nSpezielle Quantile sind der Median, die Quartile, die Quintile, die Dezile und die Perzentile:\nWir betrachten dazu in den Bespielen die Datenreihe dr an:\n# Die Zahlen von 0 bis 600 dr \u0026lt;- 0:600\r\rMedian\rDer Median (von lat. Medium für „Mitte, Mittelpunkt“ abgeleiteter Begriff mit der Bedeutung “in der Mitte gelegen”) die das 50-%-Quantil. Der Wert, welcher die Datenreihe (bestenfalls) in zwei (etwa) gleich große Abschnitte trennt. Sehr oft schreibt man \\(x_{med}\\), \\(x_{50\\%}\\), \\(x_{Med}\\) oder \\(Q_2\\) für den Median\nmedian(dr)\r## [1] 300\r\rTerzile\rAls Terile (von lat. tertius “der Dritte”) werden die beiden Quantile mit \\(p=1/3\\) und \\(p=2/3\\) bezeichnet. Sie teilen die Datenreihe in drei Abschnitte.\nquantile(dr, probs = seq(0, 1, 1/3))\r## 0% 33.33333% 66.66667% 100% ## 0 200 400 600\r\rQuartile\rDie Quartile (von lat. quartus „der Vierte“) werden die Quantile mit \\(p=25\\%\\), \\(p=50\\%\\) und \\(p=75\\%\\) bezeichnet. Sie teilen die Datenreihe in vier Abschnitte. Dabei schreibt man oft: \\(Q_1 = x_{0{,}25}\\), \\(x_{Med} = Q_2 = x_{0{,}50}\\) und \\(Q_3 = x_{0{,}75}\\) für die drei Quantile.\nquantile(dr) # oder auch: quantile(dr, probs=seq(0, 1, 1/4))\r## 0% 25% 50% 75% 100% ## 0 150 300 450 600\r\rQuintile\rQuintile (von lat. quintus “der Fünfte”) werden die Quantile mit \\(p=20\\%\\), \\(p=40\\%\\), \\(p=60\\%\\) und \\(p=80\\%\\) bezeichnet. Sie teilen die Datenreihe in fünf Abschnitte.\nquantile(dr, probs = seq(0, 1, 1/5))\r## 0% 20% 40% 60% 80% 100% ## 0 120 240 360 480 600\r\rDezile\rDie Quantile für vielfache von \\(0{,}1\\) also für \\(p=0{,}1;0{,}2;\\dots ;0{,}9\\) werden Dezile (von mittellateinisch decimalis, zu lat. decem „zehn“) genannt. Dabei heißt das \\(0{,}1\\)-Quantil das erste Dezil, das \\(0{,}2\\)-Quantil das zweite Dezil usw. Unterhalb des ersten Dezils liegen 10 % der Stichprobe, oberhalb entsprechend 90 % der Stichprobe. Ebenso liegen 40 % der Stichprobe unterhalb des vierten Dezils und 60 % oberhalb.\nquantile(dr, probs = seq(0, 1, 1/10))\r## 0% 10% 20% 30% 40% 50% 60% 70% 80% 90% 100% ## 0 60 120 180 240 300 360 420 480 540 600\r\rPerzentile\rAls Perzentile (von lat.-ital. per centum “von Hundert, Hundertstel”) werden die Quantile von \\(\\displaystyle 0{,}01\\) bis $ 0{,}99$ in Schritten von \\(0{,}01\\) bezeichnet.\nquantile(dr, probs = seq(0, 1, 1/100))\r## 0% 1% 2% 3% 4% 5% 6% 7% 8% 9% 10% 11% 12% 13% 14% ## 0 6 12 18 24 30 36 42 48 54 60 66 72 78 84 ## 15% 16% 17% 18% 19% 20% 21% 22% 23% 24% 25% 26% 27% 28% 29% ## 90 96 102 108 114 120 126 132 138 144 150 156 162 168 174 ## 30% 31% 32% 33% 34% 35% 36% 37% 38% 39% 40% 41% 42% 43% 44% ## 180 186 192 198 204 210 216 222 228 234 240 246 252 258 264 ## 45% 46% 47% 48% 49% 50% 51% 52% 53% 54% 55% 56% 57% 58% 59% ## 270 276 282 288 294 300 306 312 318 324 330 336 342 348 354 ## 60% 61% 62% 63% 64% 65% 66% 67% 68% 69% 70% 71% 72% 73% 74% ## 360 366 372 378 384 390 396 402 408 414 420 426 432 438 444 ## 75% 76% 77% 78% 79% 80% 81% 82% 83% 84% 85% 86% 87% 88% 89% ## 450 456 462 468 474 480 486 492 498 504 510 516 522 528 534 ## 90% 91% 92% 93% 94% 95% 96% 97% 98% 99% 100% ## 540 546 552 558 564 570 576 582 588 594 600\r\r\r","date":1513641600,"expirydate":-62135596800,"kind":"page","lang":"de","lastmod":1513641600,"objectID":"7ab582885ecb0b791d6e29a1c70a7966","permalink":"/nab/post/quartile-quantile-perzentile-etc/","publishdate":"2017-12-19T00:00:00Z","relpermalink":"/nab/post/quartile-quantile-perzentile-etc/","section":"post","summary":"“Was hat das eigentlich mit den Quartilen, Quantilen und so weiter auf sich?” Diese Frage kommt ab und zu in Vorlesungen zur Statistik vor. Dabei ist die Antwort recht einfach.\nQuantile\rDefinitorische Antwort\rFür eine gegebene reelle Zufallsvariable \\(X\\) heißt eine reelle Zahl \\(x_p\\) ein p-Quantil (von \\(X\\)), falls gilt:\n\\[P(X \\leq x_p) \\leq p \\quad \\text{ und }\\quad P(x_p \\leq X) \\geq 1-p.\\]\n\rWas bedeutet das denn nun konkret?","tags":["Lehre","Statistik","Wahrscheinlichkeitstheorie","R"],"title":"Quartile, Quantile, Perzentile etc.","type":"post"},{"authors":null,"categories":["Information"],"content":"GitHub bietet die Möglichkeit an, bei Interaktion mit dem Server automatisch einen Webhook zu aktivieren. Dahinter versteckt sich ein Aufruf einer URL mit einem sogenannten POST-Request. Wertet man diesen aus, so kann man z.B. nach jedem push automatisch ein fetch auf dem Webserver starten.\nIch nutze das gerade um meinen Blog immer dann zu aktualisieren, wenn ich auf dem GitHub eine Änderung vorgenommen habe.\nDamit sollte ich nie wieder vergessen alles auch auf dem Server zu aktualisieren!\nWir warten ab. ;-)\nOkay, alle Verzeichnisse sollten den richtigen Besitzer haben ;-)\nNACHTRAG: (vom 01.01.2018)\nLeider schaffe ich es nicht auf PHP heraus auch nur ein Skript auszuführen. Daher wird z.Z. alles via crontab ausgeführt. Nicht optimal, aber es läuft erstmal.\n","date":1513555200,"expirydate":-62135596800,"kind":"page","lang":"de","lastmod":1513555200,"objectID":"8bae1c962e47a4dbc47019f0954b8c82","permalink":"/nab/post/github-webhook-eingebaut/","publishdate":"2017-12-18T00:00:00Z","relpermalink":"/nab/post/github-webhook-eingebaut/","section":"post","summary":"GitHub bietet die Möglichkeit an, bei Interaktion mit dem Server automatisch einen Webhook zu aktivieren. Dahinter versteckt sich ein Aufruf einer URL mit einem sogenannten POST-Request. Wertet man diesen aus, so kann man z.B. nach jedem push automatisch ein fetch auf dem Webserver starten.\nIch nutze das gerade um meinen Blog immer dann zu aktualisieren, wenn ich auf dem GitHub eine Änderung vorgenommen habe.\nDamit sollte ich nie wieder vergessen alles auch auf dem Server zu aktualisieren!","tags":["Technisches"],"title":"GitHub Webhook eingebaut!","type":"post"},{"authors":null,"categories":["Kommentar"],"content":"Ein erster Kommentar!\n","date":1513468800,"expirydate":-62135596800,"kind":"page","lang":"de","lastmod":1513468800,"objectID":"c87272de939c1457628440d3ecd0b114","permalink":"/nab/post/first-entry/","publishdate":"2017-12-17T00:00:00Z","relpermalink":"/nab/post/first-entry/","section":"post","summary":"Ein erster Kommentar!","tags":[],"title":"First Entry","type":"post"},{"authors":null,"categories":["Fundstücke"],"content":" Gerade im Internet gefunden:\n10 Dinge die kein Talent benötigen!  Pünktlichkeit Arbeitsmoral Anstrengung Körpersprache Energie Haltung Leidenschaft Lernwillig sein Etwas mehr als das Minimum tun Vorbereitet sein  ","date":1499904000,"expirydate":-62135596800,"kind":"page","lang":"de","lastmod":1499904000,"objectID":"b726e94f17c0c4914f37e85b232b4088","permalink":"/nab/post/10-dinge-die-kein-talent-ben%C3%B6tigen/","publishdate":"2017-07-13T00:00:00Z","relpermalink":"/nab/post/10-dinge-die-kein-talent-ben%C3%B6tigen/","section":"post","summary":" Gerade im Internet gefunden:\n10 Dinge die kein Talent benötigen!  Pünktlichkeit Arbeitsmoral Anstrengung Körpersprache Energie Haltung Leidenschaft Lernwillig sein Etwas mehr als das Minimum tun Vorbereitet sein  ","tags":["Allgemein","Lehre"],"title":"10 Dinge die kein Talent benötigen!","type":"post"},{"authors":null,"categories":["Statistik"],"content":"\rDer Zentrale Grenzwertsatz der Statistik bei identischer Verteilung.\rZentraler Grenzwertsatz\rSeien \\(X_1, X_2, ..., X_n\\) unabhängige und identisch verteilte Zufallsvariablen mit bekanntem Erwartungswert \\(E(X_i) = \\mu\\) und bekannter Varianz \\(Var(X_i)=\\sigma^2\\).\nFür die Summe \\(S_n = \\sum_{i=1}^n X_i\\) ist dann der Erwartungswert \\(E(S_n)= n \\cdot \\mu\\) und die Varianz \\(Var(S_n)= n \\cdot \\sigma^2\\).\nDann gilt für die standardisierte Zufallsvariable\n\\[\r\\begin{align*}\rZ_n \u0026amp;= \\frac{\\left(\\sum\\limits_{i=1}^n X_i\\right) - n \\cdot \\mu}{\\sqrt{n\\cdot \\sigma^2}}\r= \\frac{S_n - n \\cdot \\mu}{\\sigma \\cdot \\sqrt{n}} = \\frac{n \\cdot \\bar{X}_n-n \\cdot \\mu}{\\sigma \\cdot n / \\sqrt{n}} \\\\\r\u0026amp;= \\frac{\\bar{X}_n - \\mu}{\\sigma / \\sqrt{n}} = \\frac{\\bar{X}_n - \\mu}{\\sigma} \\cdot \\sqrt{n},\r\\end{align*}\r\\]\ndass sie für wachsendes \\(n\\) immer besser durch die Standardnormalverteilung \\(N(0, 1)\\) approximiert werden kann.\nMit anderen Worten:\n\\[\rP(Z_n \\leq x) \\longrightarrow \\Phi(x), \\quad \\text{ für }\\; n \\rightarrow \\infty\r\\]\n\r\rEin Beispiel:\rNehmen wir drei Verteilungen mit Zufallsvariable \\(U\\), \\(X\\), \\(Y\\) und jeweils \\(n\\) Realisationen \\(u_1,\\dots, u_n\\), \\(x_1,\\dots, x_n\\), \\(y_1,\\dots, y_n\\).\nWählen wir zunächst \\(n=5\\):\nu\r## [1] 19.726 69.683 60.790 0.955 42.901\rx\r## [1] 7.942 15.905 12.917 6.818 4.434\ry\r## [1] 59.961 56.552 51.094 75.288 47.985\rStandardisieren wir die Werte:\nlibrary(mosaic)\rzscore(u)\r## [1] -0.6695256 1.0830283 0.7710507 -1.3280357 0.1434823\rzscore(x)\r## [1] -0.3543069 1.3440714 0.7067796 -0.5940379 -1.1025063\rzscore(y)\r## [1] 0.1677971 -0.1526624 -0.6657361 1.6085958 -0.9579944\rDie Behauptung des Zentralengrenzwertsatzes ist nun, dass mit steigender Anzahl an Werten \\(n\\) die standardisierten Werte in der empirischen Verteilungsfunktion sich immer mehr der Verteilungsfunktion der Standardnormalverteilung annähern:\nWeiterführende Literatur und Quellen dieses Eintrags:\n1. Schira, J.: Statistische Methoden der VWL und BWL. PEARSON Studion, München (2005)\n\r2. Wikipedia: Zentraler Grenzwertsatz, https://de.wikipedia.org/w/index.php?title=Zentraler_Grenzwertsatz\u0026amp;oldid=162715036, (2017)\n\r3. Weisstein, E.W.: Central limit theorem, http://mathworld.wolfram.com/CentralLimitTheorem.html, (2017)\n\r\r\r","date":1491350400,"expirydate":-62135596800,"kind":"page","lang":"de","lastmod":1491350400,"objectID":"0743c5774fc79482034a47dd5c007a5e","permalink":"/nab/post/der-zentrale-grenzwertsatz/","publishdate":"2017-04-05T00:00:00Z","relpermalink":"/nab/post/der-zentrale-grenzwertsatz/","section":"post","summary":"Der Zentrale Grenzwertsatz der Statistik bei identischer Verteilung.\rZentraler Grenzwertsatz\rSeien \\(X_1, X_2, ..., X_n\\) unabhängige und identisch verteilte Zufallsvariablen mit bekanntem Erwartungswert \\(E(X_i) = \\mu\\) und bekannter Varianz \\(Var(X_i)=\\sigma^2\\).\nFür die Summe \\(S_n = \\sum_{i=1}^n X_i\\) ist dann der Erwartungswert \\(E(S_n)= n \\cdot \\mu\\) und die Varianz \\(Var(S_n)= n \\cdot \\sigma^2\\).\nDann gilt für die standardisierte Zufallsvariable\n\\[\r\\begin{align*}\rZ_n \u0026amp;= \\frac{\\left(\\sum\\limits_{i=1}^n X_i\\right) - n \\cdot \\mu}{\\sqrt{n\\cdot \\sigma^2}}\r= \\frac{S_n - n \\cdot \\mu}{\\sigma \\cdot \\sqrt{n}} = \\frac{n \\cdot \\bar{X}_n-n \\cdot \\mu}{\\sigma \\cdot n / \\sqrt{n}} \\\\\r\u0026amp;= \\frac{\\bar{X}_n - \\mu}{\\sigma / \\sqrt{n}} = \\frac{\\bar{X}_n - \\mu}{\\sigma} \\cdot \\sqrt{n},\r\\end{align*}\r\\]","tags":["Statistik","Wahrscheinlichkeitstheorie"],"title":"Der Zentrale Grenzwertsatz","type":"post"},{"authors":null,"categories":null,"content":"","date":1486684800,"expirydate":-62135596800,"kind":"page","lang":"de","lastmod":1486684800,"objectID":"e85532955e8a35e9d46348bcbf16c22b","permalink":"/nab/project/etwas-r-am-abend/","publishdate":"2017-02-10T00:00:00Z","relpermalink":"/nab/project/etwas-r-am-abend/","section":"project","summary":"Vortrag zur Einführung in R für Studierende","tags":["R","Statistik","RStudio","Data Science","Vortrag","Lehre"],"title":"Etwas R am Abend","type":"project"},{"authors":null,"categories":null,"content":"","date":1486684800,"expirydate":-62135596800,"kind":"page","lang":"de","lastmod":1486684800,"objectID":"1acf504e26e2b9062b3965f2a5585300","permalink":"/nab/project/style.py/","publishdate":"2017-02-10T00:00:00Z","relpermalink":"/nab/project/style.py/","section":"project","summary":"Ein Pandoc Filter (in Python 3.5+ auf Basis von panflute) um Stilelemente in R markdown Dokumenten mittel geeigneter SPAN- bzw. DIV-Blöcke nach HTML bzw. LaTeX umzuwandelt.","tags":["R","R markdown","Python"],"title":"Pandoc filter: style.py","type":"project"},{"authors":null,"categories":null,"content":"","date":1486684800,"expirydate":-62135596800,"kind":"page","lang":"de","lastmod":1486684800,"objectID":"12af9b91315b5ba286d091faa36bf3d6","permalink":"/nab/project/typography.py/","publishdate":"2017-02-10T00:00:00Z","relpermalink":"/nab/project/typography.py/","section":"project","summary":"Ein Pandoc Filter (in Python 3.5+ auf Basis von panflute) um typographische Änderungen an aus  R markdown Dokumenten erzeugten HTML- bzw. LaTeX-Dokumenten vorzunehmen.","tags":["R","R markdown","Python","Pandoc","panflute","LaTeX"],"title":"Pandoc filter: typography.py","type":"project"},{"authors":null,"categories":null,"content":"Jede Sprache hat Regeln, auch Programmiersprachen und R markdown ist eine Programmiersprache. Wieso also nicht ein Tool schreiben, welches SStilregeln (engl. style guides) für R markdown kontrolliert um auch im kolaborativen Einsatz ein einheitliches \u0026ldquo;Schriftbild\u0026rdquo; des Quelltextes zu erhalten.\n\u0026hellip;\nEinen ersten Schritt habe ich mit dem Blog-Eintrag gemacht und dazu gleich noch ein Tool in Python geschrieben um Verstöße dagegen schneller zu finden.\n","date":1486684800,"expirydate":-62135596800,"kind":"page","lang":"de","lastmod":1486684800,"objectID":"e87e9dab008fda3b107138c4d47ee933","permalink":"/nab/project/rmdstylechecker/","publishdate":"2017-02-10T00:00:00Z","relpermalink":"/nab/project/rmdstylechecker/","section":"project","summary":"Python Script zum Überprüfen von Style Guidelines von R markdown Dokumenten","tags":["R","R markdown","Python"],"title":"RmdStyleChecker","type":"project"},{"authors":[],"categories":null,"content":"Click on the Slides button above to view the built-in slides feature.\n\rSlides can be added in a few ways:\n Create slides using Academic\u0026rsquo;s Slides feature and link using url_slides parameter in the front matter of the talk file Upload an existing slide deck to static/ and link using url_slides parameter in the front matter of the talk file Embed your slides (e.g. Google Slides) or presentation video on this page using shortcodes.  Further talk details can easily be added to this page using Markdown and $\\rm \\LaTeX$ math code.\n","date":1483225200,"expirydate":-62135596800,"kind":"page","lang":"de","lastmod":1483225200,"objectID":"96344c08df50a1b693cc40432115cbe3","permalink":"/nab/talk/example/","publishdate":"2017-01-01T00:00:00+01:00","relpermalink":"/nab/talk/example/","section":"talk","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam.","tags":[],"title":"Example Talk","type":"talk"},{"authors":[],"categories":null,"content":" Academic makes it easy to create a beautiful website for free using Markdown. Customize anything on your site with widgets, themes, and language packs.\nFollow our easy step by step guide to learn how to build your own free website with Academic. Check out the personal demo or the business demo of what you\u0026rsquo;ll get in less than 10 minutes.\n View the documentation Ask a question Request a feature or report a bug Updating? View the Update Guide and Release Notes Support development of Academic:  Donate a coffee Become a backer on Patreon Decorate your laptop or journal with an Academic sticker Wear the T-shirt   \nKey features:\n Easily manage various content including homepage, blog posts, publications, talks, and projects Extensible via color themes and widgets/plugins Write in Markdown for easy formatting and code highlighting, with LaTeX for mathematical expressions Social/academic network linking, Google Analytics, and Disqus comments Responsive and mobile friendly Simple and refreshing one page design Multilingual and easy to customize  Color Themes Academic is available in different color themes and font themes.\n\r\r\r\r\r\r\r\r Ecosystem  Academic Admin: An admin tool to import publications from BibTeX or import assets for an offline site Academic Scripts: Scripts to help migrate content to new versions of Academic  Install You can choose from one of the following four methods to install:\n one-click install using your web browser (recommended) install on your computer using Git with the Command Prompt/Terminal app install on your computer by downloading the ZIP files install on your computer with RStudio  Quick install using your web browser  Install Academic with Netlify  Netlify will provide you with a customizable URL to access your new site  On GitHub, go to your newly created academic-kickstart repository and edit config.toml to personalize your site. Shortly after saving the file, your site will automatically update Read the Quick Start Guide to learn how to add Markdown content. For inspiration, refer to the Markdown content which powers the Demo  Install with Git Prerequisites:\n Download and install Git Download and install Hugo   Fork the Academic Kickstart repository and clone your fork with Git:\ngit clone https://github.com/sourcethemes/academic-kickstart.git My_Website  Note that if you forked Academic Kickstart, the above command should be edited to clone your fork, i.e. replace sourcethemes with your GitHub username.\n Initialize the theme:\ncd My_Website git submodule update --init --recursive   Install with ZIP  Download and extract Academic Kickstart Download and extract the Academic theme to the themes/academic/ folder from the above step  Install with RStudio View the guide to installing Academic with RStudio\nQuick start  If you installed on your computer, view your new website by running the following command:\nhugo server  Now visit localhost:1313 and your new Academic powered website will appear. Otherwise, if using Netlify, they will provide you with your URL.\n Read the Quick Start Guide to learn how to add Markdown content, customize your site, and deploy it. For inspiration, refer to the Markdown content which powers the Demo\n Build your site by running the hugo command. Then host it for free using Github Pages or Netlify (refer to the first installation method). Alternatively, copy the generated public/ directory (by FTP, Rsync, etc.) to your production web server (such as a university\u0026rsquo;s hosting service).\n  Updating Feel free to star the project on Github to help keep track of updates and check out the release notes prior to updating your site.\nBefore updating the framework, it is recommended to make a backup of your entire website directory (or at least your themes/academic directory) and record your current version number.\nBy default, Academic is installed as a Git submodule which can be updated by running the following command:\ngit submodule update --remote --merge  Check out the update guide for full instructions and alternative methods.\nFeedback \u0026amp; Contributing Please use the issue tracker to let me know about any bugs or feature requests, or alternatively make a pull request.\nFor support, head over to the Hugo discussion forum.\nLicense Copyright 2016-present George Cushen.\nReleased under the MIT license.\n","date":1461103200,"expirydate":-62135596800,"kind":"page","lang":"de","lastmod":1515798000,"objectID":"279b9966ca9cf3121ce924dca452bb1c","permalink":"/nab/post/getting-started/","publishdate":"2016-04-20T00:00:00+02:00","relpermalink":"/nab/post/getting-started/","section":"post","summary":"Create a beautifully simple website or blog in under 10 minutes.","tags":["Academic"],"title":"Academic: the website designer for Hugo","type":"post"},{"authors":["Andreas Liefeld","Marten Völker"," Manuel Remelhe","Kai Dadhe","Sebastian Engell","Carsten Fritsch","Norman Markgaf"],"categories":null,"content":"","date":1096063200,"expirydate":-62135596800,"kind":"page","lang":"de","lastmod":1096063200,"objectID":"2e4ec66ecaba6ac511237aa249264d4d","permalink":"/nab/publication/learn2control/","publishdate":"2004-09-25T00:00:00+02:00","relpermalink":"/nab/publication/learn2control/","section":"publication","summary":"LEARN2CONTROL ist eine computergestützte Lernumgebung, die es ermöglicht, vorhandenes Grundlagenwissen im Bereich der Regelungstechnik durch selbstständiges Lernen in einem projektorientierten Umfeld zu vertiefen. Der Lernschwerpunkt liegt dabei besonders auf der Vermittlung der inneren Abhängigkeiten und Wechselwirkungen der unterschiedlichen Verfahren und Methoden der Regelungstechnik.","tags":["Projektorientiertes Lernen","Regelungstechnik"],"title":"LEARN2CONTROL – Projektorientiertes Lernen für ein besseres Gesamtverständnis in der regelungstechnischen Ausbildung","type":"publication"},{"authors":null,"categories":null,"content":" Welcome to Slides Academic\nFeatures  Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides  Controls  Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export: E  Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026quot;blueberry\u0026quot; if porridge == \u0026quot;blueberry\u0026quot;: print(\u0026quot;Eating...\u0026quot;)  Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = \\;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\nFragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}}  Press Space to play!\nOne\r Two\r Three\r\nA fragment can accept two optional parameters:\n class: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears  Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}}  Press the S key to view the speaker notes!\n Only the speaker can read these notes Press S key to view   Themes  black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links   night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links  Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026quot;/img/boards.jpg\u0026quot; \u0026gt;}} {{\u0026lt; slide background-color=\u0026quot;#0000FF\u0026quot; \u0026gt;}} {{\u0026lt; slide class=\u0026quot;my-style\u0026quot; \u0026gt;}}  Custom CSS Example Let\u0026rsquo;s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; }  Questions? Ask\nDocumentation\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"de","lastmod":-62135596800,"objectID":"c2915ec5da95791851caafdcba9664af","permalink":"/nab/slides/example-slides/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/nab/slides/example-slides/","section":"slides","summary":"Welcome to Slides Academic\nFeatures  Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides  Controls  Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export: E  Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026quot;blueberry\u0026quot; if porridge == \u0026quot;blueberry\u0026quot;: print(\u0026quot;Eating...\u0026quot;)  Math In-line math: $x + y = z$","tags":null,"title":"Slides","type":"slides"}]