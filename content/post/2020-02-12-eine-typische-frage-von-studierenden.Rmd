---
title: Eine typische Frage von Studierenden
author: admin
date: '2020-02-12'
slug: eine-typische-frage-von-studierenden
categories:
  - Statistisches
tags:
  - Lehre
  - R
  - Statistik
  - Nullhypothese
  - SBI
  - Klassische Inferenz
subtitle: ''
summary: ''
authors: []
lastmod: '2020-02-12T08:55:23+01:00'
featured: no
image:
  caption: ''
  focal_point: ''
  preview_only: no
projects: []
---
```{r setup, include=FALSE}
library(mosaic)
```

Vor kurzem fand ich mal wieder eine Anfrage einer Studierenden in meinem Email Postfach. Die Frage lautete in etwa wie folgt:

> Guten Tag Herr Markgraf,
>
> ich würde gerne die Hypothese untersuchen: Die reduzierte Abhängigkeit des Iphones tagsüber liegt am schönen Wetter.
> Dazu habe ich eine Variable "iphones.tagsüber.unbeachtet" mit 1x, 2x und 3x täglich als Ausprägungen und eine andere Variable "wetter.ist.gut", die als Ausprägung "Ja" und "Nein" hat.
> Welchen Test kann ich dazu zur Überprüfung einer Abhängigkeit nehmen?
> 
>Vielen Dank im Voraus.
>
>MfG Monika Mustermann

Natürlich ist diese Frage im Prinzip einfach zu beantworten, sogar von Leuten, die Statistik an einer Hochschule gehört haben. -- Aber da ich ja auch sonst nichts zu tun habe gebe ich gerne statistische Hilfestellung für Studierende. Sicher verdiene ich damit eigentlich Geld, also ist es nur natürlich, dass ich so etwas volllkommen unendgeldlich mache. Und wieso sollten Studierende einfach mal ein Buch in die Hand nehmen und selber nachdenken? Es gibt vermutlich keine Bücher zu diesem Thema, denn es ist gar sicher eine Geheimwissenschaft. Und wieso sollte man dann also seine Betreuungsperson zu diesem Probem fragen? -- Egal.

Was haben wir hier vorliegen? -- Im einfachsten Fall sind es zwei kategoriale Variablen und wir wollen sehen ob diese von einenander (un-)Abhängig sind.
Mangels tatsächlicher Daten basten wir uns einfach mal ein Beispiel:


### Wir basten uns ein Beispiel

```{r}
# Wie immer zuerst das Paket 'mosaic' laden
library(mosaic)

# Einen beliebigen Startwert für den Zufallszahlengenerator
# für die Reproduzierbarkeit
set.seed(123)

# Anzahl der Vorfälle insgesamt
n <- 176

# Anzahl der Wiederholungen für die SBI-Methoden
loops <- 10000

# Erfinden eines Beispieldatensatzes
daten <- data.frame(
  iphones.tagsüber.unbeachtet = sample(rep(c("1xtäglich","2xtäglich","3xtäglich"),n),n),
  wetter.ist.gut = sample(rep(c("Ja","Nein"),n),n)
)

# Ausgabe der ersten Zeilen des Datensatzes
head(daten)
```

### Ein Blick auf Kennzahlen und Visualisierungsmöglichkeiten

Man kann diese Daten als Kreuztabelle zusammenfassen und diese dann mit Hilfe eines Mosaikplots darstellen:

```{r}
tally(iphones.tagsüber.unbeachtet ~ wetter.ist.gut, data=daten)
mosaicplot(wetter.ist.gut ~ iphones.tagsüber.unbeachtet, data=daten)
```

```{r}
# Für später speichern wir die Kreuztabelle in obs.tab
obs.tab <- tally(iphones.tagsüber.unbeachtet ~ wetter.ist.gut, data=daten)
```


### Von der Forschungsthese zur Hypothese

Um nun zwischen abhänig und unabhängig statitisch zu unterscheiden, sollte man sich die Null- und Alternativhypothese genau überlegen und *operationalisieren*. 

Ein Blick auf die (orginal) Forschungsthese: "Die reduzierte Abhängigkeit des Iphones tagsüber liegt am schönen Wetter."

Okay, wir formulieren etwas um: "Es besteht ein Zusammenhang zwischen 'schönem Wetter' und dem 'Iphone tagsüber unbeachtet' lassen."

Warum diese unterschiedliche Formulierung? -- Nun, in der orginal Forschungsthese wird ein kausal Zusammenhang geprüft. Da es sich vermutlich um eine Beobachtungstudie handelt können wir einen solchen Ursache-Wirkungs-Zusammenhang aber hier nicht so einfach (bis gar nicht) prüfen. Zwar kann man von außen sagen: "Wenn es einen Zusammenhang gibt, dann führt das schöne Wetter zur Nichtbeachtung." statitisch können wir hier aber aktuell nur den Zusammenhang (und zwar ungerichtget!) testen. Liegt dieser **nicht** vor, so spricht erstmal auch nichts für einen kausalen Zusammenhang, aber ein Zusammenhang an sich spricht noch nicht für einen kausalen Zusammenhang!

Aus der umformulierten Forschungsfrage können wir die Alternativ- und auch die Nullhypothese ableiten:

**Alternativhypothese:** Es besteht ein Zusammenhang zwischen 'schönem Wetter' und dem 'Iphone tagsüber unbeachtet' lassen.

**Nullhypothese:** Es besteht **kein** Zusammenhang zwischen 'schönem Wetter' und dem 'Iphone tagsüber unbeachtet' lassen.


## Wie kann man nun den Zusammenhang *messen* und wie sieht *kein Zusammenhang* dabei aus?

Um zu sehen ob unsere Werte keinen Zusammenhang haben, also rein zufällig sind, oder es einen inneren Zusammenhang gibt müssen wir die äußeren von den inneren Häufigkeiten trennen.

Konkret heißt das, wir schauen uns an wie die Häufigkeiten oder auch Verteilung der einzelnen Variabeln ausssehen:

```{r}
tally(~ wetter.ist.gut, data=daten)
```

```{r}
tally(~ iphones.tagsüber.unbeachtet, data=daten)
```

```{r, echo=FALSE}
mh.wig <-tally(~ wetter.ist.gut, data=daten)
mh.itu <- tally(~ iphones.tagsüber.unbeachtet, data=daten)
```


#### Freiheitsgrade

Die Werte innerhalb der Kreuztabelle oben werden im wesendlichen durch diese Werte bestimmt. Die außeren Werte sind also unsere Rahmenbedingungen. Dabei ist der Einfluss der sogenannten *Randhäufigkeiten* (*Marginale Häufigkeit*) nicht zu unterschätzen. Denn wenn wir diese als *fix*/*gegeben* ansehen, können wir nur mit den sechs Werten in der Mitte unserer Kreuztabelle *spielen*.

Doch sind nicht alle sechs Werte wirklich frei wählbar. Denn um zum Beispiel die Summe `r mh.itu[1]` in der ersten Zeile zu erhalten haben wir ja die Summe von `r obs.tab[1,1]` und `r obs.tab[1,2]` gebildet.

Ist nun der Rand, also `r mh.itu[1]`, fest, so kann ich nicht *beide* Summanden frei wählen, denn 

$$`r mh.itu[1]` = `r obs.tab[1,1]` + `r obs.tab[1,2]`$$

impliziert ja, dass allgemein

$$`r mh.itu[1]` = x + y$$
gelten muss und somit durch

$$x = `r mh.itu[1]` - y \qquad\text{ bzw. }\qquad y = `r mh.itu[1]` - x$$
immer maximal eine der Variabeln -- $x$ oder $y$ -- wirklich frei wählen kann.

Da dies für jede Zeile, aber auch für jede Spalte gilt, denn z.B. ist die Summe der ersten Spalte gegeben durch

$$`r mh.wig[1]` = `r obs.tab[1,1]` + `r obs.tab[2,1]` + `r obs.tab[3,1]`,$$
sind von den sechs Werten in der Kreuztabelle in der Tat nur 2 Werte wirklich frei zu wählen. 
Wir haben also ein Problem mit *2 Freiheitsgraden*, man schreibt das kurz mit $df=2$ (*df* steht dabei für *degree of freedom*).


### Unabhängigkeit in der Statistik

Wir sagen, in der Statistik, dass ein gemeinsames Ereignis unabhängig ist wenn sich das Ereignis als Produkt der beiden Einzelereignisse berechnen lässt.
Seien $A$ und $B$ also zwei Ereignisse, dann gilt im Falle der Unabhängigkeit:

$$P(A \cap B) = P(A) \cdot P(B)$$
Oder etwas informeller: *Die Wahrscheinlichkeit das beide Ereignisse eintreffen ist das Produkt der Wahrscheinlichkeiten, dass jeweils eines der beiden Ereignisse eintrifft.*

Wir können diese Definition aus der Wahrscheinlichkeitstheorie an unser Problem adaptieren, in dem wir die Wahrscheinlichkeiten durch die relativen Häufigkeiten ersetzen.

Der Wert für das gemeinsame Ereignis `iphone.tagsüber.unbeachtet = 1xtäglich`  und das `wetter.ist.gut=ja`  wird im Falle der Unabhägigkeit durch die beiden Randhäufigkeiten bestimmt:

$$`r mh.itu[1]` \cdot `r mh.wig[1]` = `r mh.itu[1] * mh.wig[1] / n`$$

Wir können nun mit eine Kreuztabelle erstellen, wie sie seien müsste, falls wir tatsächlich *statitische Unabhängigkeit* hätten. Wir nutzen dafür eine sehr allgemein gehaltene, aber selbst programmierte, Funktion `expectation.tab()`, der wir eine Tabelle mit den Häufigkeiten der Beobachtungen geben und die uns dann die Tabelle liefert, wie sie aussehen würde, falls tatsächlich *statitische Unabhängigkeit* herrschen würde.

Die Tabelle mit den beobchteten Werten speichern wir in `obs.tab`, die der erwarteten Werte in `exp.tab`:

```{r}
expectation.tab <- function(tab.obs) {
  ret <- tab.obs
  max.i <- dim(tab.obs)[1]
  max.j <- dim(tab.obs)[2]
  
  # Randhäufigkeiten 
  x <- rep(0, max.i)
  for(i in 0:max.i) x[i] = sum(tab.obs[i,])

  y <- rep(0, max.j)
  for(j in 0:max.j) y[j] = sum(tab.obs[,j])

  # Anzahl aller Beobachtungen
  n = sum(tab.obs)
  
  for(i in 0:max.i){
    for(j in 0:max.j) {
       ret[i,j] <- (x[i] * y[j] / n)
    }
  }

  return(ret)
}

# Kreuztabelle der beobachtete Werte
obs.tab <- tally(iphones.tagsüber.unbeachtet ~ wetter.ist.gut, data=daten)

# Kreuztabelle der erwarteten Werte auf Grundlage der beobachteten Werte
exp.tab <- expectation.tab(obs.tab)
```

Schauen wir uns die beiden Tabellen kurz an. Zuerst die der beobachteten Werte:

```{r}
obs.tab
```

Dann die der erwarteten Werte:
```{r}
exp.tab
```


### Was können wir nun messen?

Unsicherheit und Zufall spielen eine große Rolle. Wir können also nicht erwarten, dass die Werte für die Kreuztabelle in der Realität genau getroffen werden. (Vorallem, weil wir hier ja mit Nachkommastellen arbeiten!) Aber wir können versuchen den Abstand zu diesen Werten zu messen. Je weiter weg die Werte in der Kreuztabelle von den theoretischen Werten liegen, um so unwarscheinlicher ist es, dass die Werte zufällig aus einer unabhängigen Population gezogen wurden. D.h. wir könnten uns für eine Abhägigkeit aussprechen.


#### Messen mit dem Absolutabstand?

Man könnte nun auf die Idee kommen die Abstände an jeder Stelle zu messen und den absoluten Abstand zu summieren:

```{r}
sum(abs(obs.tab-exp.tab))
```


Nur was sagt dieser Wert aus? -- Ist das ein kleiner Abstand oder ein großer?

Wir brauchen Referenzwerte zur Orientierung. Eine Idee lautet: **Permutationstest**

Sind die Werte unabhängig von einander, dann spielt die konkrete Zuordnung keine Rolle, sondern nur die Anzahl der Ereignisse an sich. Ordnen wir nun zufällig einem `iphones.tagsüber.unbeachtet`-Wert einen beliebigen `wetter.ist.gut`-Wert zu, dann besteht kein Zusammenhang mehr zwischen den Werten. Dies machen wir mittels `iphones.tagsüber.unbeachtet ~ shuffle(wetter.ist.gut)`.

Wir simulieren so den Zustand, dass es keine Abhängigkeit zwischen den Werten gibt.

Dabei messen wir den Abstand zwischen den Abstand zwischen den beobachteten Werten und den Werten, die wir erwarten würden, falls Unabhägigkeit vorliegen würde. Dafür nutzen wir die selbsterstellte Funktioen `diffabsobsexp`, welche die Summe der absoluten Abweichungen berechnet:

$$\text{diffabsobsexp}(obs, exp) = \sum\limits_i \left|obs_i - exp_i\right|$$

Wir Wiederholen das ganze mit Hilfe von `do(loops)` genau `loops`$=`r loops`$ mal, geben dann das Histogramm aus und tragen als rote Linie den Wert ein, die wir bei unseren beobachteten Daten tatsächliche gemessen haben:

```{r}
# Funktion zur Berechnung der absoluten Differenz zwischen
# beobachteten und erwarteten Werte
diffabsobsexp <- function(obs, exp) {
  return(sum(abs(obs-exp)))
}

# Absolute Abweichung der gemessenen Werte
obs.abs <- diffabsobsexp(obs.tab, exp.tab)

# Erzeugen der Nullverteilung
NullVert  <- do(loops) * diffabsobsexp(tally(iphones.tagsüber.unbeachtet ~ shuffle(wetter.ist.gut), data=daten), exp.tab)
gf_histogram(~ diffabsobsexp, data=NullVert) %>%
  gf_vline(xintercept = ~ obs.abs, color="red")
```

Wir können nun den p-Wert, also die relative Fläche rechts von der roten Linie in unseren Histogramm, abschätzen mit:
```{r}
prop( ~ diffabsobsexp >= obs.abs, data=NullVert)
```
```{r, echo=FALSE}
p.absobsexp <- prop( ~ diffabsobsexp >= obs.abs, data=NullVert)
```

Absolute Abweichungen (oder auch *absolute Fehler*) haben die Tendenz bei großen Zahlen auch große Abweichungswerte zu liefern und bei kleinen Werten eher kleine Abweichungswerte. 
Das kann man als Markel ansehen. 
Daher arbeitet man vielleicht lieber mit relativen Abweichungen (oder auch *relativen Fehlern*). 
Dabei setzt man die absolute Abweichung jedesmal in Bezug auf den erwarteten Wert. 
Die dazu passenden Funktion haben wir unten mit `diffabsobsexprel` implementiert. 
Dabei ist:

$$\text{diffabsobsexprel}(obs, exp) = \sum\limits_i \frac{\left|obs_i - exp_i\right|}{exp_i}$$


Wir Wiederholen das ganze mit Hilfe von `do(loops)` genau `loops`$=`r loops`$ mal, geben dann das Histogramm aus und tragen als rote Linie den Wert ein, den wir bei unseren beobachteten Daten tatsächliche gemessen haben:

```{r}
# Funktion zur Berechnung der korrigierten absoluten 
# Differenz zwischen beobachteten und erwarteten Werten
diffabsobsexprel <- function(obs, exp) {
  return(sum((abs(obs-exp))/exp))
}

# Absolute Abweichung der gemessenen Werte -- korrigiert
obs.abs <- diffabsobsexprel(obs.tab, exp.tab)

# Erzeugen der Nullverteilung
NullVert  <- do(loops) * diffabsobsexprel(tally(iphones.tagsüber.unbeachtet ~ shuffle(wetter.ist.gut), data=daten), exp.tab)
gf_dhistogram(~ diffabsobsexprel, data=NullVert) %>%
  gf_vline(xintercept = ~ obs.abs, color="red")
```


Auch hier können wir den p-Wert abschätzen:

```{r}
prop( ~ diffabsobsexprel >= obs.abs, data=NullVert)
```
```{r, echo=FALSE}
p.absobsexprel <- prop( ~ diffabsobsexprel >= obs.abs, data=NullVert)
```


**Ist der absolute Abstand überhaupt gut gewählt? -- Wäre nicht eher der quadratische Abstand angebracht?**

Ein Vorteil des quadratischen Abstand ist es, dass er kleine Abstände kleiner und große Abstände größer bewertet, als der absolute Abstand. Außerdem hat er mathematisch einige Vorteile. Wir messen nun den quadratischen Abstande mit der Funktion
 `diffquad`, die wie folgt arbeitet:
 
$$\text{diffquad}(obs, exp) = \sum\limits_i \left(obs_i - exp_i\right)^2$$

Wir Wiederholen dies nun mit Hilfe von `do(loops)` genau `loops`$=`r loops`$ mal, geben dann das Histogramm aus und tragen als rote Linie den Wert ein, den wir bei unseren beobachteten Daten tatsächliche gemessen haben:


```{r}
# Funktion zur Berechnung der quadratischen 
# Differenz zwischen beobachteten und erwarteten Werten
diffquad <- function(obs, exp) {
  return(sum((obs-exp)^2))
}

# Quadratische Abweichung der gemessenen Werte
obs.abs <- diffquad(obs.tab, exp.tab)

# Erzeugen der Nullverteilung
NullVert  <- do(loops) * diffquad(tally(iphones.tagsüber.unbeachtet ~ shuffle(wetter.ist.gut), data=daten), exp.tab)
gf_dhistogram(~ diffquad, data=NullVert) %>%
  gf_vline(xintercept = ~ obs.abs, color="red")
```

Wir können nun den p-Wert abschätzen mit:

```{r}
prop( ~ diffquad >= obs.abs, data=NullVert)
```
```{r, echo=FALSE}
p.quad <- prop( ~ diffquad >= obs.abs, data=NullVert)
```

Wie beim absoluten Abstand werden hier die Größe der Werte ausser acht gelassen und vielleicht fühlen wir uns etwas wohler, wenn wir statt des quadratischen Abstands den relativen quadratischen Abstand benutzen:

$$\text{diffquadrel}(obs, exp) = \sum\limits_i \frac{\left(obs_i - exp_i\right)^2}{exp_i}$$

Dies wiederholen wir nun mit Hilfe von `do(loops)` genau `loops`$=`r loops`$ mal, geben dann das Histogramm aus und tragen als rote Linie den Wert ein, den wir bei unseren beobachteten Daten tatsächliche gemessen haben:

```{r}
# Funktion zur Berechnung der korrigierten quadratischen 
# Differenz zwischen beobachteten und erwarteten Werten
diffquadrel <- function(obs, exp) {
  return(sum(((obs-exp)^2)/exp))
}

# Quadratische Abweichung der gemessenen Werte -- korrigiert
obs.abs <- diffquadrel(obs.tab, exp.tab)

# Erzeugen der Nullverteilung
NullVert  <- do(loops) * diffquadrel(tally(iphones.tagsüber.unbeachtet ~ shuffle(wetter.ist.gut), data=daten), exp.tab)
gf_histogram(~ diffquadrel, binwidth = 0.5, center = 0.25, data=NullVert) %>%
  gf_vline(xintercept = ~ obs.abs, color="red")
```

Den Wert `r obs.abs`, den wir mit Hilfe der relativen quadratischen Abweichung berechnet haben, nennen wir auch $\chi^2$ Wert.

Wir können nun den p-Wert abschätzen mit:

```{r}
prop( ~ diffquadrel >= obs.abs, data=NullVert)
```
```{r, echo=FALSE}
p.quadrel <- prop( ~ diffquadrel >= obs.abs, data=NullVert)
```

An Hand der p-Werte können wir nun über die Nullhypothese entscheiden:

```{r, include=FALSE}
p <- c(p.absobsexp, p.absobsexprel, p.quad, p.quadrel)
names(p) <- c("abs. Abweichung", "rel. abs. Abweichung", "quadr. Abweichung", "rel. quadr. Abweichung")
p
```


### Was sagt die klassische Statistik?

In der klassischen Statistik könnte man hier den $\chi^2$-Unabhängigkeitstest anwenden:
```{r}
xchisq.test(iphones.tagsüber.unbeachtet ~ wetter.ist.gut, data=daten)
```
```{r, eval=TRUE, echo=FALSE, include=FALSE}
xst <- xchisq.test(iphones.tagsüber.unbeachtet ~ wetter.ist.gut, data=daten)
tmp <- names(p)
p <- c(p, xst$p.value)
names(p) <- c(tmp, "ChiQuadrat-Test")
```

Vergleichen wir nun die beiden Ansätze, SBI auf der einen und der klassische Ansatz auf der anderern Seite, einmal in einem Diagramm. Das (Dichte-)Histogramm sind die Daten aus der Nullverteilung für die quadratische, korrigierte Differenz. Die rote Linie ist der gemessene Abweichungswert. Die schwarze Linie ist der Graph der $\chi^2$-Verteilung mit zwei Freiheitsgraden:

```{r}
gf_dhistogram(~ diffquadrel, binwidth = 0.5, center = 0.25, data=NullVert) %>%
  gf_fun(dchisq(x, df=2) ~ x, xlim=c(0:20), color="blue") %>% 
  gf_vline(xintercept = ~ obs.abs, color="red")
```

Aber es gibt auch den (exakten) Fisher-Test:

```{r, eval=TRUE, echo=FALSE, include=FALSE}
ft <- fisher.test(obs.tab, alternative = "greater")
tmp <- names(p)
p <- c(p, ft$p.value)
names(p) <- c(tmp, "Fisher-Test")
```

```{r}
fisher.test(obs.tab, alternative = "greater")
```


### Fazit

Wir können die p-Werte der einzelnen Tests nun gegenüber stellen:

```{r, echo=FALSE}
df <- data.frame(x = names(p), y = p)
ggplot(df, aes(x,y)) + 
  geom_col() +  
  xlab("") + 
  ylab("") +
  ylim(0, 1) +
  scale_y_continuous(breaks = c(0, 0.05, 0.10, 0.20, 0.30, 0.40, 0.50, 0.60, 0.70, 0.80, 0.90, 1.0)) +
  geom_hline(yintercept = 0.05, color="red") +
  ggtitle("Vergleich der p-Werte") +
  geom_text(aes(label = round(y,4)), position = position_stack(vjust = 0.9), color="lightgray") +
  coord_flip()
```

Was die Entscheidung für oder gegen die Nullhypothese angeht, hat jeder dieser Test (in der Regel und im Wesendlichen) die selbe Entscheidung als Konsequenz.
