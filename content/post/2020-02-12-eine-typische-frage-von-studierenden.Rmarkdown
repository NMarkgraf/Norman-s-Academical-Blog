---
title: Eine typische Frage von Studierenden
author: admin
date: '2020-02-12'
slug: eine-typische-frage-von-studierenden
categories:
  - Statistisches
tags:
  - Lehre
  - R
  - Statistik
  - Nullhypothese
  - SBI
  - Klassische Inferenz
subtitle: ''
summary: ''
authors: []
lastmod: '2020-02-12T08:55:23+01:00'
featured: no
image:
  caption: ''
  focal_point: ''
  preview_only: no
projects: []
---
```{r setup, include=FALSE}
library(mosaic)
```

Vor kurzem fand ich mal wieder eine Anfrage einer Studierenden in meinem Email Postfach. Die Frage lautete in etwa wie folgt:

> Guten Tag Herr Markgraf,
>
> ich würde gerne die Hypothese untersuchen: Die reduzierte Abhängigkeit des Iphones tagsüber liegt am schönen Wetter.
> Dazu habe ich eine Variable "iphones.tagsüber.unbeachtet" mit 1x, 2x und 3x täglich als Ausprägungen und eine andere Variable "wetter.ist.gut", die als Ausprägung "Ja" und "Nein" hat.
> Welchen Test kann ich dazu zur Überprüfung einer Abhängigkeit nehmen?
> 
>Vielen Dank im Voraus.
>
>MfG Monika Mustermann

Natürlich ist diese Frage im Prinzip einfach zu beantworten, sogar von Leuten, die Statistik an einer Hochschule gehört haben. -- Aber da ich ja auch sonst nichts zu tun habe gebe ich gerne statistische Hilfestellung für Studierende. Sicher verdiene ich damit eigentlich Geld, also ist es nur natürlich, dass ich so etwas volllkommen unendgeldlich mache. Und wieso sollten Studierende einfach mal ein Buch in die Hand nehmen und selber nachdenken? Es gibt vermutlich keine Bücher zu diesem Thema, denn es ist gar sicher eine Geheimwissenschaft. Und wieso sollte man dann also seine Betreuungsperson zu diesem Probem fragen? -- Egal.

Was haben wir hier vorliegen? -- Im einfachsten Fall sind es zwei kategoriale Variablen und wir wollen sehen ob diese von einenander (un-)Abhängig sind.
Mangels tatsächlicher Daten basten wir uns einfach mal ein Beispiel:

### Wir basten uns ein Beispiel

```{r}
library(mosaic)
set.seed(123)
n = 176
daten <- data.frame(
  iphones.tagsüber.unbeachtet = sample(rep(c("1xtäglich","2xtäglich","3xtäglich"),n),n),
  wetter.ist.gut = sample(rep(c("Ja","Nein"),n),n)
)
head(daten)
```

### Ein Blick auf Kennzahlen und Visualisierungsmöglichkeiten

Man kann diese Daten als Kreuztabelle zusammenfassen und diese dann mit Hilfe eines Mosaicplots darstellen:

```{r}
tally(iphones.tagsüber.unbeachtet ~ wetter.ist.gut, data=daten)
mosaicplot(wetter.ist.gut ~ iphones.tagsüber.unbeachtet, data=daten)
```
```{r, echo=FALSE}
obs.tab <- tally(iphones.tagsüber.unbeachtet ~ wetter.ist.gut, data=daten)
```


### Von der Forschungsthese zur Hypothese (Teil 1)

Um nun zwischen abhänig und unabhängig statitisch zu unterscheiden, sollte man sich die Null- und Alternativhypothese genau überlegen und *operationalisieren*. 

Ein Blick auf die (orginal) Forschungsthese: "Die reduzierte Abhängigkeit des Iphones tagsüber liegt am schönen Wetter."

Okay, wir formulieren etwas um: "Es besteht ein Zusammenhang zwischen 'schönem Wetter' und dem 'Iphone tagsüber unbeachtet' lassen."

Warum diese unterschiedliche Formulierung? -- Nun, in der orginal Forschungsthese wird ein kausal Zusammenhang geprüft. Da es sich vermutlich um eine Beobachtungstudie handelt können wir einen solchen Ursache-Wirkungs-Zusammenhang aber hier nicht so einfach (bis gar nicht) prüfen. Zwar kann man von außen sagen: "Wenn es einen Zusammenhang gibt, dann führt das schöne Wetter zur Nichtbeachtung." statitisch können wir hier aber aktuell nur den Zusammenhang (und zwar ungerichtget!) testen. Liegt dieser **nicht** vor, so spricht erstmal auch nichts für einen kausalen Zusammenhang, aber ein Zusammenhang an sich spricht noch nicht für einen kausalen Zusammenhang!

Aus der umformulierten Forschungsfrage können wir die Alternativ- und auch die Nullhypothese ableiten:

**Alternativhypothese:** Es besteht ein Zusammenhang zwischen 'schönem Wetter' und dem 'Iphone tagsüber unbeachtet' lassen.

**Nullhypothese:** Es besteht **kein** Zusammenhang zwischen 'schönem Wetter' und dem 'Iphone tagsüber unbeachtet' lassen.


## Wie kann man nun den Zusammenhang *messen* und wie sieht *kein Zusammenhang* dabei aus?

Um zu sehen ob unsere Werte keinen Zusammenhang haben, also rein zufällig sind, oder es einen inneren Zusammenhang gibt müssen wir die äußeren von den inneren Häufigkeiten trennen.

Konkret heißt das, wir schauen uns an wie die Häufigkeiten oder auch Verteilung der einzelnen Variabeln ausssehen:

```{r}
tally(~ wetter.ist.gut, data=daten)
tally(~ iphones.tagsüber.unbeachtet, data=daten)
```

```{r, echo=FALSE}
mh.wig <-tally(~ wetter.ist.gut, data=daten)
mh.itu <- tally(~ iphones.tagsüber.unbeachtet, data=daten)
```


#### Freiheitsgrade

Die Werte innerhalb der Kreuztabelle oben werden im wesendlichen durch diese Werte bestimmt. Die außeren Werte sind also unsere Rahmenbedingungen. Dabei ist der Einfluss der sogenannten *Randhäufigkeiten* (*Marginale Häufigkeit*) nicht zu unterschätzen. Denn wenn wir diese als *fix*/*gegeben* ansehen, können wir nur mit den sechs Werten in der Mitte unserer Kreuztabelle *spielen*

Doch sind nicht alle sechs Werte wirklich frei. Denn um zum Beispiel die Summe `r mh.itu[1]` in der ersten Zeile zu erhalten haben wir ja die Summe von `r obs.tab[1,1]` und `r obs.tab[1,2]` gebildet.

Ist nun der Rand, also `r mh.itu[1]`, fest, so kann ich die beiden Summanden nicht mehr frei wählen, denn 

$$`r mh.itu[1]` = `r obs.tab[1,1]` + `r obs.tab[1,2]`$$

impliziert ja, dass ich allgemeiner
$$`r mh.itu[1]` = x + y$$
habe und somit durch
$$x = `r mh.itu[1]` - y \qquad\text{ bzw. }\qquad y = `r mh.itu[1]` - x$$
immer nur eine der Variabeln $x$ oder $y$ wirklich frei zu wählen ist.

Da dies für jede Zeile, aber auch für jede Spalte gilt, denn z.B. ist die Summe der ersten Spalte gegeben durch

$$`r mh.wig[1]` = `r obs.tab[1,1]` + `r obs.tab[2,1]` + `r obs.tab[3,1]`,$$
sind von den sechs Werten in der Kreuztabelle in der Tat nur 2 Werte wirklich frei zu wählen. 
Wir haben also ein Problem mit *2 Freiheitsgraden*, man schreibt das kurz mit $df=2$ (*df* steht dabei für *degree of freedom*).


### Unabhängigkeit in der Statistik

Wir sagen in der Statistik, dass ein gemeinsames Ereignis unabhängig ist wenn sich das Ereignis als Produkt der beiden Einzelereignisse berechnen lässt.
Seien $A$ und $B$ also zwei Ereignisse, dann gilt im Falle der Unabhängigkeit:

$$P(A \cap B) = P(A) \cdot P(B)$$

Wir können diese Definition aus der Wahrscheinlichkeitstheorie an unser Problem adaptieren, in dem wir die Wahrscheinlichkeiten durch die relativen Häufigkeiten ersetzen.

Der Wert für das Ereignis "iphone.tagsüber.unbeachtet = 1xtäglich`  und das `wetter.ist.gut=ja` wird im Falle der Unabhägigkeit 
durch die beiden Randhäufigkeiten bestimmt:

$$`r mh.itu[1]` \cdot `r mh.wig[1]` = `r mh.itu[1] * mh.wig[1] / n`$$

Wir können nun also eine Kreuztabelle erstellen, wie sie seien müsste, falls wir tatsächlich *statitische Unabhängigkeit* hätten. Wir nutzen dafür eine sehr allgemein gehaltene Funktion `expectation.tab()`, der wir eine Tabelle mit den Häufigkeiten der Beobachtungen geben und die uns dann die Tabelle liefert, wie sie aussehen würde, falls tatsächlich *statitische Unabhängigkeit* heschen würde.
Die Tabelle mit den beobchteten Werten speichern wir in `obs.tab`, die der erwarteten Werte in `exp.tab`:

```{r}
expectation.tab <- function(tab.obs) {
  max.i <- length(tab.obs[1,])
  max.j <- length(tab.obs[,1])
  
  # Randhäufigkeiten 
  x <- rep(0, max.i)
  for(i in 0:max.i) x[i] = sum(tab.obs[,i])

  y <- rep(0, max.j)
  for(j in 0:max.j) y[j] = sum(tab.obs[j,])

    # Anzahl aller Beobachtungen
  n = sum(tab.obs)

  mtx <- c()
  
  for(i in 0:max.i){
    for(j in 0:max.j) {
       mtx <- c(mtx, (x[i] * y[j] / n))
    }
  }
  ret <- matrix(
      mtx,#rep(0, length(tab.obs)),
      nrow = max.j,
      ncol = max.i
  )
  
  # Spalten und Zeilennamen übernehmen
  colnames(ret) <- colnames(tab.obs)
  rownames(ret) <- rownames(tab.obs)
  
  return(ret)
}

obs.tab <- tally(iphones.tagsüber.unbeachtet ~ wetter.ist.gut, data=daten)
exp.tab <- expectation.tab(obs.tab)
```

Schauen wir uns die beiden Tabellen kurz an. Zuerst die der beobachteten Werte:

```{r}
obs.tab
```

Dann die der erwarteten Werte:
```{r}
exp.tab
```

### Was können wir nun messen?

Unsicherheit und Zufall spielen eine große Rolle. Wir können also nicht erwarten, dass die Werte für die Kreuztabelle in der Realität genau getroffen werden. (Vorallem, weil wir hier ja mit Nachkommastellen arbeiten!) Aber wir können versuchen den Abstand zu diesen Werten zu messen. Je weiter weg die Werte in der Kreuztabelle von den theoretischen Werten liegen, um so unwarscheinlicher ist es, dass die Werte zufällig aus einer unabhängigen Population gezogen wurden. D.h. wir könnten uns für eine Abhägigkeit aussprechen.

#### Messen mit dem Absolutabstand?

Man könnte nun auf die Idee kommen die Abstände an jeder Stelle zu messen und den absoluten Abstand zu summieren:

```{r}
sum(abs(obs.tab-exp.tab))
```


Nur was sagt dieser Wert aus? -- Ist das ein kleiner Abstand oder ein großer?

Wir brauchen Referenzwerte zur Orientierung. Die Idee: **Permutationstest**

```{r}
# Funktion zur Berechnung der absoluten Differenz zwischen
# beobachteten und erwarteten Werte
diffabsobsexp <- function(obs, exp) {
  return(sum(abs(obs-exp)))
}

# Absolute Abweichung der gemessenen Werte
obs.abs <- diffabsobsexp(obs.tab, exp.tab)

# Erzeugen der Nullverteilung
NullVert  <- do(1000) * diffabsobsexp(tally(iphones.tagsüber.unbeachtet ~ shuffle(wetter.ist.gut), data=daten), exp.tab)
gf_histogram(~ diffabsobsexp, data=NullVert) %>%
  gf_vline(xintercept = ~ obs.abs, color="red")
```

Wir können nun den p-Wert abschätzen mit:
```{r}
prop( ~ diffabsobsexp >= obs.abs, data=NullVert)
```
```{r, echo=FALSE}
p.absobsexp <- prop( ~ diffabsobsexp >= obs.abs, data=NullVert)
```

Doch haben wir alle Werte richtig bewertet? Wenn wir jeden einzelne Differenz noch durch den erwarteten Wert teilen erhalten wir:

```{r}
# Funktion zur Berechnung der korrigierten absoluten 
# Differenz zwischen beobachteten und erwarteten Werten
diffabsobsexpkor <- function(obs, exp) {
  return(sum((abs(obs-exp))/exp))
}

# Absolute Abweichung der gemessenen Werte -- korrigiert
obs.abs <- diffabsobsexpkor(obs.tab, exp.tab)

# Erzeugen der Nullverteilung
NullVert  <- do(1000) * diffabsobsexpkor(tally(iphones.tagsüber.unbeachtet ~ shuffle(wetter.ist.gut), data=daten), exp.tab)
gf_histogram(~ diffabsobsexpkor, data=NullVert) %>%
  gf_vline(xintercept = ~ obs.abs, color="red")
```

Wir können nun den p-Wert abschätzen mit:
```{r}
prop( ~ diffabsobsexpkor >= obs.abs, data=NullVert)
```
```{r, echo=FALSE}
p.absobsexpkor <- prop( ~ diffabsobsexpkor >= obs.abs, data=NullVert)
```

Ist der absolute Abstand überhaupt gut gewählt? -- Wäre nicht eher der quadratische Abstand angebracht?

```{r}
# Funktion zur Berechnung der quadratischen 
# Differenz zwischen beobachteten und erwarteten Werten
diffquad <- function(obs, exp) {
  return(sum((obs-exp)^2))
}

# Quadratische Abweichung der gemessenen Werte
obs.abs <- diffquad(obs.tab, exp.tab)

# Erzeugen der Nullverteilung
NullVert  <- do(1000) * diffquad(tally(iphones.tagsüber.unbeachtet ~ shuffle(wetter.ist.gut), data=daten), exp.tab)
gf_histogram(~ diffquad, data=NullVert) %>%
  gf_vline(xintercept = ~ obs.abs, color="red")
```
Wir können nun den p-Wert abschätzen mit:
```{r}
prop( ~ diffquad >= obs.abs, data=NullVert)
```
```{r, echo=FALSE}
p.quad <- prop( ~ diffquad >= obs.abs, data=NullVert)
```
Wenn man nun den quadratischen Abstand noch durch die Erwartung teilt:

```{r}
# Funktion zur Berechnung der korrigierten quadratischen 
# Differenz zwischen beobachteten und erwarteten Werten
diffquadkor <- function(obs, exp) {
  return(sum(((obs-exp)^2)/exp))
}

# Quadratische Abweichung der gemessenen Werte -- korrigiert
obs.abs <- diffquadkor(obs.tab, exp.tab)

# Erzeugen der Nullverteilung
NullVert  <- do(1000) * diffquadkor(tally(iphones.tagsüber.unbeachtet ~ shuffle(wetter.ist.gut), data=daten), exp.tab)
gf_histogram(~ diffquadkor, data=NullVert) %>%
  gf_vline(xintercept = ~ obs.abs, color="red")
```
Wir können nun den p-Wert abschätzen mit:
```{r}
prop( ~ diffquadkor >= obs.abs, data=NullVert)
```
```{r, echo=FALSE}
p.quadkor <- prop( ~ diffquadkor >= obs.abs, data=NullVert)
```

An Hand der p-Werte können wir nun über die Nullhypothese entscheiden:
```{r, include=FALSE}
p <- c(p.absobsexp, p.absobsexpkor, p.quad, p.quadkor)
names(p) <- c("abs. Abweichung", "kor. abs. Abweichung", "quadr. Abweichung", "kor. quadr. Abweichung")
p
```

### Was sagt die klassische Statistik?

In der klassischen Statistik könnte man hier den $\chi^2$-Unabhängigkeitstest anwenden:
```{r}
xchisq.test(iphones.tagsüber.unbeachtet ~ wetter.ist.gut, data=daten)
```
```{r, eval=TRUE, echo=FALSE, include=FALSE}
xst <- xchisq.test(iphones.tagsüber.unbeachtet ~ wetter.ist.gut, data=daten)
tmp <- names(p)
p <- c(p, xst$p.value)
names(p) <- c(tmp, "ChiQuadrat-Test")
```

Aber es gibt auch den (exakten) Fisher-Test:

```{r, eval=TRUE, echo=FALSE, include=FALSE}
ft <- fisher.test(obs.tab, alternative = "greater")
tmp <- names(p)
p <- c(p, ft$p.value)
names(p) <- c(tmp, "Fisher-Test")
```

```{r}
fisher.test(obs.tab, alternative = "greater")
```

### Fazit

Wir können die p-Werte der einzelnen Tests nun gegenüber stellen:
```{r, echo=FALSE}
p
```

Was die Entscheidung für oder gegen die Nullhypothese angeht, hat jeder dieser Test (in der Regel) die selbe Entscheidung als Konsequenz.
